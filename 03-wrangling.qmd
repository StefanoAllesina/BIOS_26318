# Data wrangling

## Goal

Learn how to manipulate large data sets by writing efficient, consistent, and compact code. Introduce the use of `dplyr`, `tidyr`, and the "pipe" operator `|>`. Effortlessly produce statistics for grouped data. Massage data into "tidy" form.

## What is data wrangling?

As biologists living in the XXI century, we are often faced with tons of data, possibly replicated over several organisms, treatments, or locations. We would like to streamline and automate our analysis as much as possible, writing scripts that are easy to read, fast to run, and easy to debug. Base `R` can get the job done, but often the code contains complicated operations, and a lot of `$` signs and brackets.

We're going to learn about the packages `dplyr` and `tidyr`, which are part of `tidyverse` and can be used to manipulate large data frames in a simple and straightforward way. These tools are also much faster than the corresponding base `R` commands, are very compact, and can be concatenated into "pipelines".

We are going to use the data set `penguins` from the package `palmerpenguins`, which we have already seen last week.

```{webr-r}
library(palmerpenguins) # a nice data set to play with
# make sure function select is the right one...
select <- dplyr::select
```

## A new data type, `tibble`

The data is stored in a "tibble":

```{webr-r}
class(penguins)
```

In fact, `dplyr` ships with a new data type, called a `tibble`. To convert a `data.frame` into a tibble, use `as_tibble`:

```{webr-r}
# load a data frame
data("trees")
class(trees)
trees <- as_tibble(trees)
class(trees)
```

The nice feature of `tbl` objects is that they will print only what fits on the screen, and also give you useful information on the size of the data, as well as the type of data in each column. Other than that, a `tbl` object behaves very much like a `data.frame`. In some rare cases, you want to transform the `tbl` back into a `data.frame`. For this, use the function `as.data.frame(tbl_object)`.

We can take a look at the data using one of several functions:

-   `head(dt)` shows the first few rows
-   `tail(dt)` shows the last few rows
-   `glimpse(dt)` a summary of the data (similar to `str` in base R)
-   `View(dt)` open in spreadsheet-like window

## Selecting rows and columns

There are many ways to subset the data, either by row (subsetting the *observations*), or by column (subsetting the *variables*). For example, let's select only the rows with observations from the island `Torgersen`:

```{webr-r}
filter(penguins, island == "Torgersen")
```

We have 52 observations. We have used the command `filter(tbl, conditions)` to select certain observations. We can combine several conditions, by listing them side by side, possibly using logical operators.

> **Exercise:** what does this do? `filter(penguins,  bill_length_mm > 40,  bill_depth_mm > 20, sex == male)`

We can also select particular variables (columns) using the function `select(tbl, cols to select)`. For example, select `species` and `island`:

```{webr-r}
select(penguins, species, island)
```

How many `species` are represented in the data set? We can use the function `distinct(tbl, cols to select)` to retain only the rows that differ from each other:

```{webr-r}
distinct(select(penguins, species))
```

Showing that there are three species, once we removed the duplicates. There are many other ways to subset observations:

-   `slice_sample(tbl, howmany, replace = TRUE)` sample `howmany` rows at random (with replacement)
-   `sample_sample(tbl, proportion, replace = FALSE)` sample a certain proportion (e.g. `0.2` for 20%) of rows at random without replacement
-   `slice(tbl, 5:20)` extract the rows `5` to `20`
-   `slice_max(penguins, 10, body_mass_g)` extract the first `10` rows, once ordered by `body_mass_g`

More ways to select columns:

-   `select(penguins, contains("mm"))` select all columns containing the string `mm`
-   `select(penguins, -year, -body_mass_g)` exclude the columns `year` and `body_mass_g`
-   `select(penguins, matches("length|bill"))` select all columns whose names match a regular expression

## Creating pipelines using `|>`

We've been calling nested functions, such as `distinct(select(penguins, species))`. If you have to add another layer or two, the code would become unreadable. `dplyr` allows you to "un-nest" these functions and create a "pipeline" in which you concatenate commands separated by a special operator, `|>`. For example:

```{webr-r}
penguins |> # take a data table
  select(species) |> # select a column
  distinct() # remove duplicates
```

does exactly the same operations as the command above, but is much more readable. By concatenating many commands, you can create incredibly complex pipelines while retaining readability. It is also quite easy to add another piece of the pipeline in between commands, or to comment some of the pipeline out.

Another advantage of pipelines is that they help with name completion. In fact, `RStudio` is running in the background your pipeline while you type it. Try typing `dt |> filter(` and then start typing `bill` and press `Tab`: you will see the options to complete the column name; choose it with your arrows and hit `Return`. The back tick-marks will be added automatically if needed (e.g., column names containing spaces, or starting with a digit).

## Producing summaries

Sometimes we need to calculate statistics on certain columns. For example, calculate the average body mass of the penguins. We can do this using `summarise` (you can use British or American spelling):

```{webr-r}
penguins |> 
  summarise(avg = mean(body_mass_g, na.rm = TRUE))
# alternatively, drop_na(body_mass_g) removes all the observations for which
# body_mass_g is NA
penguins |> 
  drop_na(body_mass_g) |> 
  summarise(avg = mean(body_mass_g, na.rm = TRUE))
```

where we used `na.rm = TRUE` to ignore missing values. This command returns a `tbl` object with just the average body mass. You can combine multiple statistics (use `first`, `last`, `min`, `max`, `n` \[count the number of rows\], `n_distinct` \[count the number of distinct rows\], `mean`, `median`, `var`, `sd`, etc.):

```{webr-r}
penguins |> 
  summarise(avg = mean(body_mass_g, na.rm = TRUE), 
            sd = sd(body_mass_g, na.rm = TRUE), 
            median = median(body_mass_g, na.rm = TRUE))
```

## Summaries by group

One of the most useful features of `dplyr` is the ability to produce statistics for the data once subsetted by *groups*. For example, we would like to compute the average body mass by species and sex:

```{webr-r}
penguins |> 
  drop_na() |> 
  group_by(sex, species) |> 
  summarise(mean = mean(body_mass_g, na.rm = TRUE))
```

showing that male penguins are heavier for the three species considered.

> **Exercise:** find the average `bill_depth_mm` and `bill_length_mm` by `species` and `sex`. Filter the data to consider only observations for the year 2008.

## Ordering the data

To order the data according to one or more variables, use `arrange()`:

```{webr-r}
penguins |> 
  arrange(body_mass_g) # ascending
penguins |> 
  arrange(desc(body_mass_g)) # descending
```

## Renaming columns

To rename one or more columns, use `rename()`:

```{webr-r}
penguins |> 
  rename(bm = body_mass_g)
```

## Adding new variables using mutate

If you want to add one or more new columns, with the content being a function of other columns, use the function `mutate`. For example, we are going to add a new column showing the z-score for the body mass of each individual:

```{webr-r}
penguins |> 
  mutate(zscore_bm = scale(body_mass_g)) |> 
  select(species, sex, body_mass_g, zscore_bm)
```

We can pipe the results to `ggplot` for plotting!

```{webr-r}
penguins |> 
  mutate(zscore_bm = scale(body_mass_g)) |> 
  select(species, sex, body_mass_g, zscore_bm) |> 
  ggplot() + aes(x = species, y = zscore_bm, colour = sex) + 
    geom_jitter()
```

You can use the function `transmute()` to create a new column and drop the original columns.

Most importantly, you can use `mutate` and `transmute` on grouped data. For example, let's recompute the z-score of the `body_mass_g` once the data is grouped by species and sex:

```{webr-r}
penguins |> 
  drop_na() |> 
  select(species, sex, body_mass_g) |> 
  group_by(species, sex) |> 
  mutate(zscore_bm = scale(body_mass_g)) |> 
  arrange(body_mass_g)
```

## Data wrangling

Data is rarely in a format that is good for computing, and much effort goes into reading the data and wrestling with it to make it into a good format. As the name implies, `tidyverse` strongly advocates for the use of data in *tidy* form. What does this mean?

-   Each variable forms a column
-   Each observation forms a row
-   Each type of observational unit forms a table

This is often called *narrow table* format. Any other form of data (e.g., *wide table* format) is considered *messy*. However, often data are not organized in tidy form, or we want to produce tables for human consumption rather than computer consumption. The package `tidyr` allows to accomplish just that. It contains only a few, very powerful functions. To explore this issue, we build a data set containing the average body mass by species and sex:

```{webr-r}
penguin_bm <- penguins |> 
  drop_na() |> 
  group_by(sex, species) |> 
  summarise(body_mass = mean(body_mass_g), .groups = "drop") # remove groups after calculation

penguin_bm
```

## From narrow to wide

Our data is in tidy form. For a paper, we want to show the difference between males and females in a table:

```{webr-r}
penguin_bm |> 
  pivot_wider(names_from = sex, values_from = body_mass)
```

where we have created new column names using the values found in `sex` (hence, `names_from`), and filled each cell with the corresponding value found in `body_mass` (hence, `values_from`). Similarly, if we want to show the data with species as column names, and sex as rows, we can use:

```{webr-r}
penguin_bm |> 
  pivot_wider(names_from = species, values_from = body_mass)
```

## From wide to narrow

For a real-world example, we will make data from:

> *Tree-ring analysis for sustainable harvest of Millettia stuhlmannii in Mozambique*, I.A.D.Remane M.D.Therrell, **South African Journal of Botany** Volume 125, September 2019, Pages 120-125

You can read a tab-separated file from:

```{webr-r}
dt <- read_tsv("https://raw.githubusercontent.com/StefanoAllesina/BIOS_26318/master/data/annual_increment.txt") |> 
  select(Age, contains("CAT"))
# selecting only age and samples
```

Each column besides `YEAR` represents a single tree, and each cell contains the diameter (in cm) of the tree when it was at a given age. To make this in tidy form, we first create the columns `tree` and `diameter`:

```{webr-r}
dt <- dt |> 
  pivot_longer(-Age, names_to = "tree", values_to = "diameter")
```

and then remove the NAs:

```{webr-r}
dt <- dt |> filter(!is.na(diameter))
```

Now it is easy to plot the growth trajectory of each tree (as in Fig. 3 of the original paper):

```{webr-r}
dt |> 
  ggplot() + 
  aes(x = Age, y = diameter) + 
  geom_line(aes(group = tree)) + # note---this makes a line for each tree
  geom_smooth(method = "loess") # while the smoothing function considers all trees
```

## Separate: split a column into two or more

```{webr-r}
test <- tibble(name = c("Allesina, Stefano", "Kondrashov, Dmitry", "Mir, Amatullah"))
test
```

```{webr-r}
test |> separate(name, into = c("last_name", "first_name"), sep = ", ")
```

The complement of `separate` is called `unite`.

## Separate rows: from one row to many

```{webr-r}
test <- tibble(id = c(1, 2, 3, 4), records = c("a;b;c", "c;d", "a;e", "f"))
test
```

To make it into tidy form, only one record per row:

```{webr-r}
test |> separate_rows(records, sep = ";")
```

## Example: brown bear, brown bear, what do you see?

This exercise uses a dataset from [GBIF](https://www.gbif.org/en/), the Global Biodiversity Information Facility. You can download the latest version yourself by doing the following (but just skip ahead if you want to use the data provided by us).

1.  Go to [GBIF](https://www.gbif.org/en/) and click on Occurrences.
2.  Under Scientific Name type in *Ursus arctos* (brown bear), and hit enter.
3.  To download the data, create an account on GBIF
4.  Then click on Download, and select Simple (which should have a tab-delimited .csv file)
5.  Save to the data folder in your working folder.

If you don't want to go through all this, you can load this previously downloaded file called `Ursus_GBIF.csv` from our GitHub repository. The code in the following chunk loads and displays the contents of the tibble:

```{webr-r}
# you will need ggmap!
require(ggmap)
Ursus_data <- read_tsv("https://raw.githubusercontent.com/StefanoAllesina/BIOS_26318/master/data/Ursus_GBIF.csv")
glimpse(Ursus_data)
```

You see there are 50 variables in the data set, so it may be useful to remove the ones we don't need. For this exercise, our objective is to plot the occurrences of this species on the world map, so we need two variables for certain: `decimalLatitude` and `decimalLongitude`, as well as the `BasisofRecord` for additional information. Use your `tidyverse` skills to create a new tibble with only those variables. In addition, remove duplicate records from the tibble.

```{webr-r}
# your code goes here!
```

Now we can plot this data set on the world map, using the useful package maps. To plot, use the `ggplot()` syntax with the following addition:

```{webr-r}
mapWorld <- borders("world", colour="gray50", fill="gray50") # create a layer of borders
# now you can call 
# ggplot() + mapWorld + ...
```

Note the warning message generated by `ggplot`. Then consider the map with the locations of the brown bear specimens. Do any of them seem strange to you? What may be the explanation behind these strange data point? Now filter out the points that you identified as suspicious and print out their BasisofRecord. Does this suggest an explanation for the strangeness?

```{webr-r}
# your code goes here!
```

## Resources

-   [R for Data Science](https://hackr.io/tutorial/r-for-data-science)
-   A [cool class](https://cfss.uchicago.edu/syllabus.html) at U of C in Social Sciences
-   [Data transformation](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) cheat sheet
-   [Dealing with dates](https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf) cheat sheet
-   [Data import](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf) cheat sheet
