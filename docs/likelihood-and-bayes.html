<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Lecture 7 Likelihood and Bayes | Fundamentals of Biological Data Analysis</title>
<meta name="author" content="Dmitry Kondrashov and Stefano Allesina">
<meta name="description" content="understand the difference between likelihood and probability maximum likelihood estimation calculate positive predictive value of a hypothesis test interpret the results of Bayesian inference  7.1...">
<meta name="generator" content="bookdown 0.24.1 with bs4_book()">
<meta property="og:title" content="Lecture 7 Likelihood and Bayes | Fundamentals of Biological Data Analysis">
<meta property="og:type" content="book">
<meta property="og:description" content="understand the difference between likelihood and probability maximum likelihood estimation calculate positive predictive value of a hypothesis test interpret the results of Bayesian inference  7.1...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lecture 7 Likelihood and Bayes | Fundamentals of Biological Data Analysis">
<meta name="twitter:description" content="understand the difference between likelihood and probability maximum likelihood estimation calculate positive predictive value of a hypothesis test interpret the results of Bayesian inference  7.1...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0.9000/transition.js"></script><script src="libs/bs3compat-0.3.0.9000/tabs.js"></script><script src="libs/bs3compat-0.3.0.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentals of Biological Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Organization of the class</a></li>
<li><a class="" href="refresher.html"><span class="header-section-number">1</span> Refresher</a></li>
<li><a class="" href="visualizing-data-using-ggplot2.html"><span class="header-section-number">2</span> Visualizing data using ggplot2</a></li>
<li><a class="" href="fundamentals-of-probability.html"><span class="header-section-number">3</span> Fundamentals of probability</a></li>
<li><a class="" href="data-wrangling.html"><span class="header-section-number">4</span> Data wrangling</a></li>
<li><a class="" href="distributions-and-their-properties.html"><span class="header-section-number">5</span> Distributions and their properties</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">6</span> Hypothesis testing</a></li>
<li><a class="active" href="likelihood-and-bayes.html"><span class="header-section-number">7</span> Likelihood and Bayes</a></li>
<li><a class="" href="review-of-linear-algebra.html"><span class="header-section-number">8</span> Review of linear algebra</a></li>
<li><a class="" href="linear-models.html"><span class="header-section-number">9</span> Linear models</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> ANOVA</a></li>
<li><a class="" href="time-series-modeling-and-forecasting.html"><span class="header-section-number">11</span> Time series: modeling and forecasting</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">12</span> Generalized linear models</a></li>
<li><a class="" href="model-selection.html"><span class="header-section-number">13</span> Model Selection</a></li>
<li><a class="" href="principal-component-analysis.html"><span class="header-section-number">14</span> Principal Component Analysis</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">15</span> Clustering</a></li>
<li><a class="" href="building-phylogeneric-trees.html"><span class="header-section-number">16</span> Building phylogeneric trees</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="likelihood-and-bayes" class="section level1" number="7">
<h1>
<span class="header-section-number">Lecture 7</span> Likelihood and Bayes<a class="anchor" aria-label="anchor" href="#likelihood-and-bayes"><i class="fas fa-link"></i></a>
</h1>
<ul>
<li>understand the difference between likelihood and probability</li>
<li>maximum likelihood estimation</li>
<li>calculate positive predictive value of a hypothesis test</li>
<li>interpret the results of Bayesian inference</li>
</ul>
<div id="likelihood-and-estimation" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Likelihood and estimation<a class="anchor" aria-label="anchor" href="#likelihood-and-estimation"><i class="fas fa-link"></i></a>
</h2>
<div id="likelihood-vs.-probability" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> likelihood vs. probability<a class="anchor" aria-label="anchor" href="#likelihood-vs.-probability"><i class="fas fa-link"></i></a>
</h3>
<p>In everyday English, probability and likelihood are synonymous. In probability and statistics, however, the two are distinct, although related, concepts. The definition of likelihood is based on the notion of conditional probability that we defined in week 2, applied to a data set and a particular probability model <span class="math inline">\(M\)</span>:</p>
<p><span class="math display">\[ 
L(M \ \ \vert \ \ D) = P(D \ \ \vert \ \ M)
\]</span></p>
<p>The model is based on a set of assumptions that allow us to calculate probabilities of outcomes of a random experiment, typically a random variable with a well-defined probability distribution function.</p>
<p><strong>Example.</strong> <span class="math inline">\(M\)</span> may represent the binomial random variable, based on the assumptions that the data are strings of <span class="math inline">\(n\)</span> independent binary outcomes with a set probability <span class="math inline">\(p\)</span> of “success.” We then have the following formula for the probability of obtaining <span class="math inline">\(k\)</span> successes:</p>
<p><span class="math display">\[ 
P(k ; n , p) =  {n \choose k} p^k (1-p)^{n-k}
\]</span></p>
<p>Suppose we think we have a fair coin and we flip it ten times and obtain 4 heads and 6 tails. Then the likelihood of our model (a binomial random variable with <span class="math inline">\(p=0.5\)</span> with <span class="math inline">\(n=10\)</span>) based on our data (<span class="math inline">\(k=4\)</span>) is:</p>
<p><span class="math display">\[
L(p=0.5, n=10 \ \vert \ k=4 ) = P(k =4 \ \vert \ n=10 , p=0.5) = {10 \choose 4} 0.5^4 (0.5)^{6}
\]</span></p>
<p>To calculate this precisely, it is easiest to use the R function dbinom():</p>
<div class="sourceCode" id="cb465"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">4</span>,<span class="fl">10</span>,<span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 0.2050781</code></pre>
<p>So the likelihood of this data set being produced by a fair coin is about 20.5%.</p>
<p>This certainly looks like a probability — in fact we calculated it from a probability distribution function, so why do we call it a likelihood? There are two fundamental differences between the two, one mostly abstract, the other more grounded.</p>
<p>First, a model (or model parameters) is not a random variable, because it comes from an assumption we made in our heads, not from an outcome of a random process. This may seem to be an abstract, almost philosophical distinction, but how would you go about assigning probabilities to all the models one can come up with? Would they vary from person to person, because one may prefer to use the binomial random variable, and another prefers Poisson? You see how this can get dicey if we think of these in terms of the traditional “frequency of outcomes” framework of probability.</p>
<p>Second, and more quantitatively relevant, is that likelihoods do not satisfy the fundamental axiom of probability: they do not add up to one. Remember that probabilities were defined on a sample space of all outcomes of a random experiment. Likelihoods apply to models or their parameters, and there are usually uncountably many models - in fact it’s not possible to even describe all the possible models in vague terms! Even if we agree that we’re evaluating only one type of model, e.g. the binomial random variable, the likelihood parameter <span class="math inline">\(p\)</span> does not work like a probability, because there is a non-zero likelihood for any value <span class="math inline">\(p\)</span> (technically, the coin could have any degree of unfairness!) so adding up all of the likelihoods will results in infinity.</p>
</div>
<div id="maximizing-likelihood" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> maximizing likelihood<a class="anchor" aria-label="anchor" href="#maximizing-likelihood"><i class="fas fa-link"></i></a>
</h3>
<p>One of the most common applications of likelihood is to find the model or model parameters that give the highest likelihood based on the data, and call those the best statistical estimate. Here are the symbols we will use in this discussion:</p>
<ul>
<li>
<span class="math inline">\(D\)</span>: the observed data</li>
<li>
<span class="math inline">\(\theta\)</span>: the free parameter(s) of the statistical model</li>
<li>
<span class="math inline">\(L(\theta \ \vert \ D)\)</span>: the likelihood function, read “the likelihood of <span class="math inline">\(\theta\)</span> given the data”</li>
<li>
<span class="math inline">\(\hat{\theta}\)</span>: the maximum-likelihood estimates (m.l.e.) of the parameters</li>
</ul>
</div>
<div id="discrete-probability-distributions" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> discrete probability distributions<a class="anchor" aria-label="anchor" href="#discrete-probability-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>The simplest case is that of a probability distribution function that takes discrete values. Then, the likelihood of <span class="math inline">\(\theta\)</span> given the data is simply the probability of obtaining the data when parametrizing the model with parameters <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[L(\theta \ \vert \ D) = P(X = D \ \vert \ \theta)\]</span></p>
<p>Finding the m.l.e. of <span class="math inline">\(\theta\)</span> simply means finding the value(s) maximizing the probability of obtaining the given data under the model. In cases when this likelihood function has a simple algebraic form, we can find the maximum value using the classic method of taking its derivative and setting it to zero.</p>
<p><strong>Example.</strong> Let’s go back to the binomial example. Based on the data set of 4 heads out of 10 coin tosses, what is the maximum likelihood estimate of the probability of a head <span class="math inline">\(p\)</span>? The range of values of <span class="math inline">\(p\)</span> is between 0 and 1, and since we have a functional expression for <span class="math inline">\(P(k=4 ; n=10, p)\)</span> (see above) we can plot it using the dbinom() function:</p>
<div class="sourceCode" id="cb467"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">10</span>
<span class="va">k</span> <span class="op">&lt;-</span> <span class="fl">4</span>
<span class="va">pl</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0</span>, y <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.window.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">like_fun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">lik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="va">k</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">lik</span><span class="op">)</span>
<span class="op">}</span>
<span class="va">pl</span> <span class="op">&lt;-</span> <span class="va">pl</span> <span class="op">+</span> <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">like_fun</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">xlab</span><span class="op">(</span><span class="st">'probability of success (p)'</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">ylab</span><span class="op">(</span><span class="st">'likelihood'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">geom_vline</span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fl">0.4</span>, linetype<span class="op">=</span><span class="st">'dotted'</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span>
<span class="fu">show</span><span class="op">(</span><span class="va">pl</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-186-1.png" width="672"></div>
<p>It’s probably not surprising that the maximum of the likelihood function occurs at <span class="math inline">\(p=0.4\)</span>, that is the observed fraction of heads! Using the magic of derivatives, we can show that for a data set with <span class="math inline">\(k\)</span> success out of <span class="math inline">\(n\)</span> trials, the maximum likelihood value of <span class="math inline">\(p\)</span> is <span class="math inline">\(\hat p = k/n\)</span>:</p>
<p><span class="math display">\[ 
L(p  \ \vert \ n, k) = {n \choose k} p^k (1-p)^{n-k} \\
L'(p | n, k ) = {n \choose k}\left [ kp^{k-1}(1-p)^{n-k} - (n-k) (1-p)^{n-k-1}p^k \right] ={n \choose k} p^{k-1} (1-p)^{n-k-1} \left [ k(1-p) - (n-k)p \right] = 0 \\
k(1-p) = (n-k)p \\
\hat p = k/n
\]</span></p>
</div>
<div id="continuous-probability-distributions" class="section level3" number="7.1.4">
<h3>
<span class="header-section-number">7.1.4</span> continuous probability distributions<a class="anchor" aria-label="anchor" href="#continuous-probability-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>The definition is more complex for continuous variables (because <span class="math inline">\(P(X = x; \theta) = 0\)</span> as there are infinitely many values…). What is commonly done is to use the <em>density function</em> <span class="math inline">\(f(x; \theta)\)</span> and considering the probability of obtaining a value <span class="math inline">\(x \in [x_j, x_j + h]\)</span>, where <span class="math inline">\(x_j\)</span> is our observed data point, and <span class="math inline">\(h\)</span> is small. Then:</p>
<p><span class="math display">\[
L(\theta \ \vert \ x_j) = \lim_{h \to 0^+} \frac{1}{h} \int_{x_j}^{x_j + h} f(x ; \theta) dx = f(x_j ; \theta)
\]</span></p>
<p>Note that, contrary to probabilities, density values can take values greater than 1. As such, when the dispersion is small, one could end up with values of likelihood greater than 1 (or positive log-likelihoods). In fact, the likelihood function is proportional to but not necessarily equal to the probability of generating the data given the parameters: <span class="math inline">\(L(\theta\vert X) \propto P(X; \theta)\)</span>.</p>
<p>Most classical statistical estimations are based on maximizing a likelihood function. For example, linear regression estimates of slope and intercept are based on minimizing the sum of squares, or more generally, the <span class="math inline">\(\chi\)</span>-squared statistic. This amounts to maximizing the likelihood of the underlying model, which is based on the assumptions of normally distributed independent residuals.</p>
</div>
</div>
<div id="bayesian-thinking" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Bayesian thinking<a class="anchor" aria-label="anchor" href="#bayesian-thinking"><i class="fas fa-link"></i></a>
</h2>
<p>We will formalize the process of incorporation of prior knowledge into probabilistic inference by going back to the notion of conditional probability introduced in week 2. First, if you multiply both sides of the definition by <span class="math inline">\(P(B)\)</span>, then we obtain the probability of the intersection of events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:
<span class="math display">\[P(A \cap B) = P(A \ \vert \ B) P(B); \;  P(A \cap B) = P(B \ \vert \ A) P(A) \]</span>
Second, we can partition a sample space into two complementary sets, <span class="math inline">\(A\)</span> and <span class="math inline">\(\bar A\)</span>, and then the set of <span class="math inline">\(B\)</span> can be partitioned into two parts, that intersect with <span class="math inline">\(A\)</span> and <span class="math inline">\(\bar A\)</span>, respectively, so that the probability of <span class="math inline">\(B\)</span> is
<span class="math display">\[P(B) = P(A \cap B) + P( \bar A\cap B)\]</span></p>
<p>The two formulas together lead to a very important result called the <em>law of total probability</em>:
<span class="math display">\[
P(B) =  P(B \ \vert \ A) P(A) + P(B \ \vert \ \bar A)P(\bar A)
\]</span></p>
<p>It may not be clear at first glance why this is useful: after all, we replaced something simple (<span class="math inline">\(P(B)\)</span>) with something much more complex on the right hand side. You will see how this formula enables us to calculate quantities that are not otherwise accessible.</p>
<p><strong>Example:</strong> Suppose we know that the probability of a patient having a disease is 1% (called the prevalence of the disease in a population), and the sensitivity and specificity of the test are both 80%. What is the probability of obtaining a negative test result for a randomly selected patient? Let us call <span class="math inline">\(P(H) = 0.99\)</span> the probability of a healthy patient and <span class="math inline">\(P(D) = 0.01\)</span> the probability of a diseased patient. Then:
<span class="math display">\[ P(Neg) =  P(Neg  \ \vert \  H) P(H) + P(Neg  \ \vert \  D)P(D)  = \]</span>
<span class="math display">\[ = 0.8 \times 0.99 + 0.2 \times 0.01 = 0.794\]</span></p>
<div id="bayes-formula" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> Bayes’ formula<a class="anchor" aria-label="anchor" href="#bayes-formula"><i class="fas fa-link"></i></a>
</h3>
<p>Take the first formula in this section, which expresses the probability <span class="math inline">\(P(A \cap B)\)</span> in two different ways. Since the expressions are equal, we can combine them into one equation, and by dividing both sides by <span class="math inline">\(P(B)\)</span>, we obtain what’s known as <em>Bayes’ formula</em>:
<span class="math display">\[ P(A \ \vert \ B) = \frac{P(B \ \vert \ A) P(A)}{P(B) }\]</span></p>
<p>Another version of Bayes’ formula re-writes the denominator using the Law of total probability above:
<span class="math display">\[
P(A \ \vert \ B) = \frac{P(B \ \vert \ A)P(A)}{P(B \ \vert \ A) P(A) + P(B \ \vert \ \bar A)P( \bar A)}
\]</span></p>
<p>Bayes’ formula gives us the probability of <span class="math inline">\(A\)</span> given <span class="math inline">\(B\)</span> from probabilities of <span class="math inline">\(B\)</span> given <span class="math inline">\(A\)</span> and given <span class="math inline">\(-A\)</span>, and the prior (baseline) probability of <span class="math inline">\(P(A)\)</span>. This is enormously useful when it is easy to calculate the conditionals one way and not the other. Among its many applications, it computes the effect of a test result with given sensitivity and specificity (conditional probabilities) on the probability of the hypothesis being true.</p>
</div>
<div id="positive-predictive-value" class="section level3" number="7.2.2">
<h3>
<span class="header-section-number">7.2.2</span> positive predictive value<a class="anchor" aria-label="anchor" href="#positive-predictive-value"><i class="fas fa-link"></i></a>
</h3>
<p>In reality, a doctor doesn’t have the true information about the patient’s health, but rather the information from the test and hopefully some information about the population where she is working. Let us assume we know the rate of false positives <span class="math inline">\(P(Pos \ \vert \ H\)</span>) and the rate of false negatives <span class="math inline">\(P(Neg \ \vert \  D)\)</span>, as well as the prevalence of the disease in the whole population <span class="math inline">\(P(D)\)</span>. Then we can use Bayes’ formula to answer the practical question, if the test result is positive, what is the probability the patient is actually sick? This is called the <em>positive predictive value</em> of a test. The deep Bayesian fact is that one cannot make inferences about the health of the patient after the test without some prior knowledge, specifically the prevalence of the disease in the population:</p>
<p><span class="math display">\[ P(D  \ \vert \  Pos) =  \frac{P(Pos \ \vert \ D)P(D)}{P(Pos \ \vert \ D) P(D) + P(Pos  \ \vert \  H)P(H)}\]</span></p>
<p><strong>Example.</strong> Suppose the test has a 0.01 probability of both false positive and false negatives, and the overall prevalence of the disease in the population 0.02. You may be surprised that from an epidemiological perspective, a positive result is far from definitive:</p>
<p><span class="math display">\[ P(D  \ \vert \  Pos)  = \frac{0.99 \times 0.02}{0.99 \times 0.02 + 0.01 \times 0.98} = 0.67 \]</span></p>
<p>This is because the disease is so rare, that even though the test is quite accurate, there are going to be a lot of false positives (about 1/3 of the time) since 98% of the patients are healthy.</p>
<p>We can also calculate the probability of a patient who tests negative of actually being healthy, which is called the <em>negative predictive value</em>. In this example, it is far more definitive:</p>
<p><span class="math display">\[ P(H  \ \vert \  Neg)  = \frac{P(Neg \ \vert \ H)P(H)}{P(Neg \ \vert \ H) P(H) + P(Neg  \ \vert \  D)P(D)} = \]</span></p>
<p><span class="math display">\[ = \frac{0.99 \times 0.98}{0.99 \times 0.98 + 0.01 \times 0.02} =  0.9998\]</span>
This is again because this disease is quite rare in this population, so a negative test result is almost guaranteed to be correct. In another population, where disease is more prevalent, this may not be the case.</p>
<div class="figure">
<img src="images/prob_tree_tikz1.png" alt=""><p class="caption">Bayesian hypothesis testing tree with prior probability 0.1</p>
</div>
<div class="figure">
<img src="images/prob_tree_tikz2.png" alt=""><p class="caption">Bayesian hypothesis testing tree with prior probability 0.01</p>
</div>
<p><strong>Exercise:</strong> Simulate medical testing by rolling dice for a rare disease (1/6 prevalence) and a common disease (1/2 prevalence), with both sensitivity and specificity of 5/6. Compare the positive predictive values for the two cases.</p>
</div>
<div id="prosecutors-fallacy" class="section level3" number="7.2.3">
<h3>
<span class="header-section-number">7.2.3</span> prosecutor’s fallacy<a class="anchor" aria-label="anchor" href="#prosecutors-fallacy"><i class="fas fa-link"></i></a>
</h3>
<p>The basic principle of Bayesian thinking is that one cannot interpret the reliability of a result, e.g. a hypothesis test, without factoring in the prior probability of it being true. This seems like a commonsensical concept, but it is often neglected when such results are interpreted in various contexts, which can lead to perilous mistakes.</p>
<p>Here is a scenario called “the prosecutor’s fallacy.” Suppose that a defendant is accused of a crime, and physical evidence collected at the crime scene matches this person (e.g. a fingerprint or a DNA sample), but no other evidence exists to connect the defendant to the crime. The prosecutor calls an expert witness to testify that fewer than one out of a million randomly chosen people would match this sample. Therefore, she argues, there is overwhelming probability that the defendant is guilty and less than 1 in a million chance they are innocent.</p>
<p>Do you spot the problem with the argument?</p>
<p>It’s the same fallacy as we saw in the medical testing scenario, or that is portrayed in the xkcd cartoon above. The prosecutor is conflating the probability of a match (positive result) given that the person is innocent, and the probability of the person being innocent, given the match. The probability of the former is one in a million, but we want to know the latter! And the latter depends on the prior probability of the person committing the crime, which should have been investigated by the detectives: did the defendant have a conflict with the victim or have they never met? did he have opportunity to commit the crime, or was he in a different city at the time? Without this information, it is impossible to decide whether it’s more likely that the DNA/fingerprint match is a false positive (in a country of 300 million, you can find 300 false matches if everyone is in the database!) or a true positive.</p>
</div>
<div id="reproducibility-in-science" class="section level3" number="7.2.4">
<h3>
<span class="header-section-number">7.2.4</span> reproducibility in science<a class="anchor" aria-label="anchor" href="#reproducibility-in-science"><i class="fas fa-link"></i></a>
</h3>
<p>In 2005 John Ioannidis published a paper entitled <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">“Why most published research findings are false”</a>. The paper, as you can see by its title, was intended to be provocative, but it is based solidly on the classic formula of Bayes. The motivation for the paper came from the observation that too often in modern science, big, splashy studies that were published could not be reproduced or verified by other researchers. What could be behind this epidemic of questionable scientific work?</p>
<p>The problem as described by Ioannidis and many others, in a nutshell, is that unthinking use of traditional hypothesis testing leads to a high probability of false positive results being published. The paper outlines several ways in which this can occur.</p>
<p>Too often, a hypothesis is tested and if the resultant p-value is less than some arbitrary threshold (very often 0.05, an absurdly high number), then the results are published. However, if one is testing a hypothesis with low prior probability, a positive hypothesis test result is very likely a false positive. Very often, modern biomedical research involves digging through a large amount of information, like an entire human genome, in search for associations between different genes and a phenotype, like a disease. It is a priori unlikely that any specific gene is linked to a given phenotype, because most genes have very specific functions, and are expressed quite selectively, only at specific times or in specific types of cells. However, publishing such studies results in splashy headlines (“Scientists find a gene linked to autism!”) and so a lot of false positive results are reported, only to be refuted later, in much less publicized studies.</p>
<p>Ioannidis performed basic calculations of the probability that a published study is true (that is, that a positive reported result is a true positive), and how it is affected by pre-study (prior) probability, number of conducted studies on the same hypothesis, and the level of bias. His prediction is that for fairly typical scenario (e.g. pre-study probability of 10%, ten groups working simultaneously, and a reasonable amount of bias) the probability that a published result is correct is less than 50%. He then followed up with another paper [2] that investigated 49 top-cited medical research publications over a decade, and looked at whether follow-up studies could replicate the results, and found that a very significant fraction of their findings could not be replicated or were found to have weaker effects by subsequent investigations.</p>
</div>
</div>
<div id="bayesian-inference" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Bayesian inference<a class="anchor" aria-label="anchor" href="#bayesian-inference"><i class="fas fa-link"></i></a>
</h2>
<p>As an alternative to frequentist and maximum likelihood approaches to modeling biological data, Bayesian statistics has seen an impressive growth in recent years, due to the improved computational power.</p>
<p>At the heart of Bayesian inference is an application of Bayes’ theorem: take a model with parameters <span class="math inline">\(\theta\)</span>, and some data <span class="math inline">\(D\)</span>. Bayes’ theorem gives us a disciplined way to “update” our belief in the distribution of <span class="math inline">\(\theta\)</span> once we’ve seen the data <span class="math inline">\(D\)</span>:</p>
<p><span class="math display">\[
P(\theta \ \vert \ D) = \frac{P(D \ \vert \ \theta) P(\theta)}{P(D)}
\]</span>
where:</p>
<ul>
<li>
<span class="math inline">\(P(\theta \ \vert \ D)\)</span> is the <strong>posterior distribution</strong> of <span class="math inline">\(\theta\)</span>, i.e., our updated belief in the values of <span class="math inline">\(\theta\)</span>.</li>
<li>
<span class="math inline">\(P(D \ \vert \ \theta)\)</span> is the <strong>likelihood function</strong>: <span class="math inline">\(P(DX \ \vert \ \theta) = L(\theta \ \vert \ D)\)</span>.</li>
<li>
<span class="math inline">\(P(\theta)\)</span> is the <strong>prior distribution</strong>, i.e. our belief on the distribution of <span class="math inline">\(\theta\)</span> before seeing the data.</li>
<li>
<span class="math inline">\(P(D)\)</span> is called the <strong>evidence</strong>: <span class="math inline">\(P(D) = \int P(D \ \vert \ \theta) d \theta\)</span> (in practice, this need not to be calculated).</li>
</ul>
<div id="example-capture-recapture" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Example: capture-recapture<a class="anchor" aria-label="anchor" href="#example-capture-recapture"><i class="fas fa-link"></i></a>
</h3>
<p>There is a well-established method in population ecology of estimating the size of a population by repeatedly capturing and tagging a number of individuals and later repeating the experiment to see how many are recaptured. Suppose that <span class="math inline">\(n\)</span> were captured initially and <span class="math inline">\(k\)</span> were recaptured later. We assume that the probability <span class="math inline">\(p\)</span> of recapturing an individual is the same for all individuals. Then our likelihood function is once again, based on the binomial distribution.</p>
<p><span class="math display">\[
L(p \ \vert \ k, n) = \binom{n}{k}p^k (1-p)^{n-k}
\]</span>
and our maximum likelihood estimate is <span class="math inline">\(\hat{p} = k /n\)</span>. This allows for estimation of the total population size to be <span class="math inline">\(P = n_2/\hat p\)</span>, where <span class="math inline">\(n_2\)</span> is the total number of individuals captured in the second experiment. There are more sophisticated estimators, but this one is reasonable for large enough populations.</p>
<p>Let us plot the likelihood as a function of <span class="math inline">\(p\)</span> for the case in which <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(k = 33\)</span></p>
<div class="sourceCode" id="cb468"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fl">33</span>
<span class="va">pl</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0</span>, y <span class="op">=</span> <span class="fl">0</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.window.html">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">likelihood_function</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">lik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Special.html">choose</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">m</span><span class="op">)</span> <span class="op">*</span> <span class="va">p</span><span class="op">^</span><span class="va">m</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="va">p</span><span class="op">)</span><span class="op">^</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="va">m</span><span class="op">)</span>
  <span class="co"># divide by the evidence to make into density function</span>
  <span class="kw"><a href="https://rdrr.io/r/base/function.html">return</a></span><span class="op">(</span><span class="va">lik</span> <span class="op">*</span> <span class="op">(</span><span class="va">n</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span>
<span class="va">pl</span> <span class="op">&lt;-</span> <span class="va">pl</span> <span class="op">+</span> <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">likelihood_function</span><span class="op">)</span>
<span class="fu">show</span><span class="op">(</span><span class="va">pl</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-189-1.png" width="672"></div>
<p>Now we choose a prior. For convenience, we choose a Beta distribution, <span class="math inline">\(P(p) = \text{Beta}(\alpha, \beta) = \frac{p^{\alpha - 1} (1-p)^{\beta - 1}}{B(\alpha, \beta)}\)</span>, where <span class="math inline">\(B(\alpha, \beta)\)</span> is the Beta function, <span class="math inline">\(B(\alpha, \beta) = \int_0^1 t^{\alpha -1} (1-t)^{\beta - 1} dt\)</span>.</p>
<p>Therefore:</p>
<p><span class="math display">\[
P(p \ \ \vert \ \ m,n) \propto L(p \ \ \vert \ \ m,n) P(p) = \left(\binom{n}{m} p^m (1-p)^{n-m} \right) \left( \frac{p^{\alpha - 1} (1-p)^{\beta - 1}}{B(\alpha, \beta)} \right) \propto p^{m+\alpha -1} (1-p)^{n-m + \beta -1} \propto \text{Beta}(m + \alpha, \beta + m - n)
\]</span></p>
<p>We can explore the effect of choosing a prior on the posterior. Suppose that in the past we have seen probabilities close to 50%. Then we could choose a prior <span class="math inline">\(\text{Beta}(10,10)\)</span> (this is what is called a “strong” or “informative” prior). Let’s see what happens to the posterior:</p>
<div class="sourceCode" id="cb469"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># a strong prior</span>
<span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">10</span>
<span class="va">beta</span> <span class="op">&lt;-</span> <span class="fl">10</span>
<span class="va">prior_function</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span>
<span class="va">posterior_function</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">p</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p</span>, <span class="va">alpha</span> <span class="op">+</span> <span class="va">m</span>, <span class="va">beta</span> <span class="op">+</span> <span class="va">n</span> <span class="op">-</span> <span class="va">m</span><span class="op">)</span>
<span class="va">pl</span> <span class="op">+</span> <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">prior_function</span>, colour <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">posterior_function</span>, colour <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-190-1.png" width="672"></div>
<p>You can see that the posterior “mediates” between the prior and the likelihood curve. When we use a weak prior, then our posterior will be closer to the likelihood function:</p>
<div class="sourceCode" id="cb470"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># a weak prior</span>
<span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>
<span class="va">beta</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>
<span class="va">pl</span> <span class="op">+</span> <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">prior_function</span>, colour <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">stat_function</span><span class="op">(</span>fun <span class="op">=</span> <span class="va">posterior_function</span>, colour <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-191-1.png" width="672"></div>
<p>The fact that the posterior depends on the prior is the most controversial aspect of Bayesian inference. Different schools of thought treat this feature differently (e.g., “Subjective Bayes” interprets priors as beliefs before seeing the data; “Empirical Bayes” relies on previous experiments or on the data themselves to derive the prior; “Objective Bayes” tries to derive the least-informative prior given the data). In practice, the larger the data, the cleaner the signal, the lesser the influence of the prior on the resulting posterior.</p>
</div>
<div id="mcmc" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> MCMC<a class="anchor" aria-label="anchor" href="#mcmc"><i class="fas fa-link"></i></a>
</h3>
<p>The type of calculation performed above is feasible only for very simple models, and for appropriately chosen priors (called “conjugate priors”). For more complex models, we rely on simulations. In particular, one can use Markov-Chain Monte Carlo (MCMC) to sample from the posterior distribution of complex models. Very briefly, one builds a Markov-Chain in which the states represent sets of parameters; parameters are sampled from the prior, and the probability of moving to one state to another is proportional to the difference in their likelihood. When the MC converges, then one obtains the posterior distribution of the parameters.</p>
<p>Bayesian inference is used for many complex problems, including phylogenetic tree building [5].</p>
</div>
</div>
<div id="reading" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Reading:<a class="anchor" aria-label="anchor" href="#reading"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p><a href="https://www.r-bloggers.com/maximum-likelihood-estimation-from-scratch/">Maximum likelihood estimation from scratch</a></p></li>
<li><p><a href="https://academic.oup.com/mbe/article/24/8/1586/1103731">Phylogenetic Analysis by Maximum Likelihood</a></p></li>
<li><p><a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Why most published scientific studies are false</a></p></li>
<li><p><a href="https://jamanetwork.com/journals/jama/fullarticle/201218">Contradicted and Initially Stronger Effects in Highly Cited Clinical Research</a></p></li>
<li><p><a href="http://nbisweden.github.io/MrBayes/">MrBayes</a></p></li>
<li><p><a href="https://www.molecularecologist.com/2016/02/quick-and-dirty-tree-building-in-r/">Quick and Dirty Tree Building in R</a></p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Mark_and_recapture">Mark and Recapture</a></p></li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="hypothesis-testing.html"><span class="header-section-number">6</span> Hypothesis testing</a></div>
<div class="next"><a href="review-of-linear-algebra.html"><span class="header-section-number">8</span> Review of linear algebra</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#likelihood-and-bayes"><span class="header-section-number">7</span> Likelihood and Bayes</a></li>
<li>
<a class="nav-link" href="#likelihood-and-estimation"><span class="header-section-number">7.1</span> Likelihood and estimation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#likelihood-vs.-probability"><span class="header-section-number">7.1.1</span> likelihood vs. probability</a></li>
<li><a class="nav-link" href="#maximizing-likelihood"><span class="header-section-number">7.1.2</span> maximizing likelihood</a></li>
<li><a class="nav-link" href="#discrete-probability-distributions"><span class="header-section-number">7.1.3</span> discrete probability distributions</a></li>
<li><a class="nav-link" href="#continuous-probability-distributions"><span class="header-section-number">7.1.4</span> continuous probability distributions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bayesian-thinking"><span class="header-section-number">7.2</span> Bayesian thinking</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#bayes-formula"><span class="header-section-number">7.2.1</span> Bayes’ formula</a></li>
<li><a class="nav-link" href="#positive-predictive-value"><span class="header-section-number">7.2.2</span> positive predictive value</a></li>
<li><a class="nav-link" href="#prosecutors-fallacy"><span class="header-section-number">7.2.3</span> prosecutor’s fallacy</a></li>
<li><a class="nav-link" href="#reproducibility-in-science"><span class="header-section-number">7.2.4</span> reproducibility in science</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bayesian-inference"><span class="header-section-number">7.3</span> Bayesian inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#example-capture-recapture"><span class="header-section-number">7.3.1</span> Example: capture-recapture</a></li>
<li><a class="nav-link" href="#mcmc"><span class="header-section-number">7.3.2</span> MCMC</a></li>
</ul>
</li>
<li><a class="nav-link" href="#reading"><span class="header-section-number">7.4</span> Reading:</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentals of Biological Data Analysis</strong>" was written by Dmitry Kondrashov and Stefano Allesina. It was last built on 2021-09-24.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
