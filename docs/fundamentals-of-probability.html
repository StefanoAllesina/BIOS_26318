<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Lecture 3 Fundamentals of probability | Fundamentals of Biological Data Analysis</title>
<meta name="author" content="Dmitry Kondrashov and Stefano Allesina">
<meta name="description" content="3.1 Sample spaces and random variables No observation or measurement in our world is perfectly reproducible, no matter how carefully planned and executed. The level of uncertainly varies, but...">
<meta name="generator" content="bookdown 0.24.1 with bs4_book()">
<meta property="og:title" content="Lecture 3 Fundamentals of probability | Fundamentals of Biological Data Analysis">
<meta property="og:type" content="book">
<meta property="og:description" content="3.1 Sample spaces and random variables No observation or measurement in our world is perfectly reproducible, no matter how carefully planned and executed. The level of uncertainly varies, but...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lecture 3 Fundamentals of probability | Fundamentals of Biological Data Analysis">
<meta name="twitter:description" content="3.1 Sample spaces and random variables No observation or measurement in our world is perfectly reproducible, no matter how carefully planned and executed. The level of uncertainly varies, but...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.0.9000/transition.js"></script><script src="libs/bs3compat-0.3.0.9000/tabs.js"></script><script src="libs/bs3compat-0.3.0.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentals of Biological Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Organization of the class</a></li>
<li><a class="" href="refresher.html"><span class="header-section-number">1</span> Refresher</a></li>
<li><a class="" href="visualizing-data-using-ggplot2.html"><span class="header-section-number">2</span> Visualizing data using ggplot2</a></li>
<li><a class="active" href="fundamentals-of-probability.html"><span class="header-section-number">3</span> Fundamentals of probability</a></li>
<li><a class="" href="data-wrangling.html"><span class="header-section-number">4</span> Data wrangling</a></li>
<li><a class="" href="distributions-and-their-properties.html"><span class="header-section-number">5</span> Distributions and their properties</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">6</span> Hypothesis testing</a></li>
<li><a class="" href="likelihood-and-bayes.html"><span class="header-section-number">7</span> Likelihood and Bayes</a></li>
<li><a class="" href="review-of-linear-algebra.html"><span class="header-section-number">8</span> Review of linear algebra</a></li>
<li><a class="" href="linear-models.html"><span class="header-section-number">9</span> Linear models</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> ANOVA</a></li>
<li><a class="" href="time-series-modeling-and-forecasting.html"><span class="header-section-number">11</span> Time series: modeling and forecasting</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">12</span> Generalized linear models</a></li>
<li><a class="" href="model-selection.html"><span class="header-section-number">13</span> Model Selection</a></li>
<li><a class="" href="principal-component-analysis.html"><span class="header-section-number">14</span> Principal Component Analysis</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">15</span> Clustering</a></li>
<li><a class="" href="building-phylogeneric-trees.html"><span class="header-section-number">16</span> Building phylogeneric trees</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="fundamentals-of-probability" class="section level1" number="3">
<h1>
<span class="header-section-number">Lecture 3</span> Fundamentals of probability<a class="anchor" aria-label="anchor" href="#fundamentals-of-probability"><i class="fas fa-link"></i></a>
</h1>
<div id="sample-spaces-and-random-variables" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Sample spaces and random variables<a class="anchor" aria-label="anchor" href="#sample-spaces-and-random-variables"><i class="fas fa-link"></i></a>
</h2>
<p>No observation or measurement in our world is perfectly reproducible, no matter how carefully planned and executed. The level of uncertainly varies, but randomness always finds a way to creep into a data set. Where does the “random” factor come from? From the classical physics perspective, as articulated by Laplace, most natural phenomena are theoretically deterministic for an omniscient being with an unlimited computational power. Quantum mechanical phenomena are (theoretically) truly random, but the randomness is not observable on the scales of biology or social science. The lack of predictability in the data we work with is usually due either to its intrinsic complexity (e.g., bio-molecular systems, prediction of animal behavior), which essentially makes it impossible to know every detail of the system, or to some external source of noise (e.g., measurement error, weather affecting food availability) that is outside of our control.</p>
<p>In probability terminology, a <em>random experiment</em> produces <em>outcomes</em> and the collection of all outcomes of an experiment is called its <em>sample space</em>.</p>
<p><strong>Example:</strong> The specifics of the experiment can affect the degree of uncertainty in the outcome; the same measurement may be random or not, depending on context. For example, measuring the height of a person should be deterministic, if one measures the height of the same person within a short amount of time. So unless you’re interested in studying the error in <a href="https://www.quickmedical.com/measure/stadiometer.html">stadiometer</a> results, you probably won’t consider this a random experiment. However, measuring the heights of different people is a random experiment, where the source of randomness is primarily due to the selection of people for your study, called <em>sampling error</em>, rather than due to the measurement noise of any one person.</p>
<p>The measurement of interest from a random experiment is called a <em>random variable</em>. Sometimes the measurement is simply the outcome, but usually it reports some aspect of the outcome and so several outcomes can have the same value of the random variable. The random variable can then be seen as condensing the sample space into a smaller range of values. Random variables can be <em>numeric</em> or <em>categorical</em>, with the difference that categorical variables cannot be assigned meaningful numbers. For instance, one may report an individual by phenotype (e.g., white or purple flowers), or having a nucleotide A, T, G, C in a particular position, and although one could assign numbers to these categories (e.g., 1, 2, 3, 4) they could not be used in a sensible way—one can compare and do arithmetic with numbers, but A is not less than T and A + T does not equal G. Thus there are different tools for describing and working with numeric and categorical random variables.</p>
<p><strong>Example:</strong> In a DNA sequence a codon triplet represents a specific amino acid, but there is redundancy (several triplets may code for the same amino acid). One may think of a coding DNA sequence as an outcome, but the amino acid (sequence or single one) as a random variable. Extending this framework, one may think of genotype as an outcome, but a phenotype (e.g., eye color) as a random variable—although this is not correct for any phenotype that is not strictly determined by the genotype, because then there are other factors (e.g., environmental or epigenetic) that influence the value of the random variable besides the outcome (genotype).</p>
<p><strong>Exercise:</strong> The package <code>palmerpenguins</code> contains multiple variables measured in populations of three different species of penguins over three years on three different islands. Identify numeric and categorical variables, and specify whether numeric variables are discrete and continuous.</p>
<div class="sourceCode" id="cb292"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://allisonhorst.github.io/palmerpenguins/">palmerpenguins</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">penguins</span><span class="op">)</span></code></pre></div>
<pre><code>## tibble [344 × 8] (S3: tbl_df/tbl/data.frame)
##  $ species          : Factor w/ 3 levels "Adelie","Chinstrap",..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ island           : Factor w/ 3 levels "Biscoe","Dream",..: 3 3 3 3 3 3 3 3 3 3 ...
##  $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...
##  $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...
##  $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...
##  $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...
##  $ sex              : Factor w/ 2 levels "female","male": 2 1 1 NA 1 2 1 2 NA NA ...
##  $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...</code></pre>
</div>
<div id="probability-axioms" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Probability axioms<a class="anchor" aria-label="anchor" href="#probability-axioms"><i class="fas fa-link"></i></a>
</h2>
<p>An outcome in sample space can be assigned a <em>probability</em> depending on its frequency of occurrence out of many trials, each is a number between 0 and 1. Combinations of outcomes (<em>events</em>) can be assigned probabilities by building them out of individual outcomes. These probabilities have a few rules, called the <em>axioms of probability</em>, expressed using set theory notation.</p>
<ol style="list-style-type: decimal">
<li><p>The total probability of all outcomes in sample space is 1. <span class="math inline">\(P(\Omega) = 1\)</span></p></li>
<li><p>The probability of nothing (empty set) is 0. <span class="math inline">\(P(\emptyset) = 0\)</span></p></li>
<li><p>The probability of an event made up of the union of two events is the sum of the two probabilities minus the probability of the overlap (intersection.) <span class="math inline">\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)</span></p></li>
</ol>
<p><strong>Example:</strong> Let’s assign a probability to every possible three-letter codon. There are <span class="math inline">\(4^3 = 64\)</span> codons, so if one assumes that each one has equal probability, then they they all equal <span class="math inline">\(1/64\)</span> (by axiom 1.) The probability of a codon having A as the first letter is 1/4, and so is the probability of A as the second letter. Axiom 3 allows us to calculate the probability of A in either the first or the second letter:</p>
<p><span class="math display">\[ P(AXX \cup \ XAX ) =  P(AXX) + P(XAX) - P(AAX) = 1/4 + 1/4 - 1/16 = 7/16\]</span></p>
</div>
<div id="probability-distributions" class="section level2" number="3.3">
<h2>
<span class="header-section-number">3.3</span> Probability distributions<a class="anchor" aria-label="anchor" href="#probability-distributions"><i class="fas fa-link"></i></a>
</h2>
<p>The probability of each value of a random variable can be calculated from the probability of the event that corresponds to each value of the random variable. The collection of the probabilities of all of the values of the random variable is called the <em>probability distribution function</em> of the random variable, more formally the <em>mass function</em> for a discrete random variable or the <em>density function</em> for a continuous random variable.</p>
<p>For a discrete random variable (let’s call it <span class="math inline">\(X\)</span>) with a probability mass function <span class="math inline">\(f\)</span>, the probability of <span class="math inline">\(X\)</span> taking the value of <span class="math inline">\(a\)</span> can be written either as <span class="math inline">\(f(X=a)\)</span> or <span class="math inline">\(f(a)\)</span>, as long as it’s clear that <span class="math inline">\(f\)</span> is the probability distribution function of <span class="math inline">\(X\)</span>. The one ironclad rule of probability is that all values of the mass function have to add up to 1. To state this mathematically, if all the possible values of <span class="math inline">\(X\)</span> can be written as <span class="math inline">\(a_1, a_2, ...\)</span> (there may be finitely or infinitely many of them, as long as it’s a countable infinity), this sum has to be equal to 1:
<span class="math display">\[ \sum_i f(a_i) = 1 \]</span></p>
<p>A continuous random variable (let’s call it <span class="math inline">\(Y\)</span>) with a probability density function <span class="math inline">\(g\)</span> is a bit more complicated. The continuous part means that the random variable has uncountably many values, even if the range is finite (for example, there are uncountably many real numbers between 0 and 1). Thus, the probability of any single value must be vanishingly small (zero), otherwise it would be impossible to add up (integrate) all of the values and get a finite result (let alone 1). We can only measure the probability of a range of values of <span class="math inline">\(Y\)</span> and it is defined by the integral of the density function overall that range:</p>
<p><span class="math display">\[ P( a&lt; Y &lt; b) = \int_a ^b g(y) dy \]</span></p>
<p>The total probability over the entire range of <span class="math inline">\(Y\)</span> has to be 1, but it’s similarly calculated by integration instead of summation (<span class="math inline">\(R\)</span> represents the range of values of <span class="math inline">\(Y\)</span>):</p>
<p><span class="math display">\[ \int_R g(y) dy = 1\]</span></p>
<p><strong>Example:</strong> As codons (DNA triplets) code for amino acids, we can consider the genetic code a random variable on the sample space. Assuming all codons have equal probabilities, the probability of each amino acid is the number of triplets that code for it divided by 64. For example, the probabilities of leucine and arginine are <span class="math inline">\(6/64 = 3/32\)</span>, the probability of threonine is <span class="math inline">\(4/64 = 1/16\)</span> and the probabilities of methionine and tryptophan are <span class="math inline">\(1/64\)</span>. This defines a probability distribution function of the random variable of the genetic code. Note that the sum of all the probabilities of amino acids has to be 1. Of course there is no inherent reason why each triplet should be equally probable, so a different probability structure on the sample space would result in a different probability distribution (mass) function.</p>
</div>
<div id="measures-of-center-medians-and-means" class="section level2" number="3.4">
<h2>
<span class="header-section-number">3.4</span> Measures of center: medians and means<a class="anchor" aria-label="anchor" href="#measures-of-center-medians-and-means"><i class="fas fa-link"></i></a>
</h2>
<p>The standard measures described here are applicable only numeric random variables. Some measures of center and spread for categorical variables exist as well.</p>
<p>The <em>median</em> of a random variable is the value which is in the middle of the distribution, specifically, that the probability of the random variable being no greater than that value is 0.5.</p>
<p>The <em>mean</em> or <em>expectation</em> of a random variable is the center of mass of the probability distribution. Specifically, it is defined for a mass function to be:</p>
<p><span class="math display">\[ E(X) = \sum_i a_i\, f(a_i)\]</span></p>
<p>And for a density function it is defined using the integral:
<span class="math display">\[ E(Y) =  \int_R y\, g(y) dy \]</span></p>
<p><strong>Example:</strong> Let us examine the factors (categorical variables) in the penguins data set. They cannot be described using means and medians, but can be plotted by counts in each category as you learned in the introduction to <code>ggplot2</code>:</p>
<div class="sourceCode" id="cb294"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">penguins</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">species</span>, fill <span class="op">=</span> <span class="va">sex</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_bar</span><span class="op">(</span>position <span class="op">=</span> <span class="st">"fill"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-110-1.png" width="672"></div>
<div class="sourceCode" id="cb295"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">penguins</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="va">year</span>, fill <span class="op">=</span> <span class="va">species</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">geom_bar</span><span class="op">(</span>position <span class="op">=</span> <span class="st">"fill"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-110-2.png" width="672"></div>
<p>One can plot the distributions of numeric variables like body mass for different penguin species using box plots:</p>
<div class="sourceCode" id="cb296"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">penguins</span><span class="op">)</span> <span class="op">+</span> <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">species</span><span class="op">)</span>, y<span class="op">=</span><span class="va">body_mass_g</span><span class="op">)</span> <span class="op">+</span> <span class="fu">geom_boxplot</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## Warning: Removed 2 rows containing non-finite values (stat_boxplot).</code></pre>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-111-1.png" width="672"></div>
<p>The following code chunk uses <code>dplyr</code> functions that we will learn in the next chapter to calculate the mean and median values of these variables aggregated by species:</p>
<div class="sourceCode" id="cb298"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penguins</span> <span class="op">%&gt;%</span> <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">species</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">body_mass_g</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   species    mean
##   &lt;fct&gt;     &lt;dbl&gt;
## 1 Adelie    3706.
## 2 Chinstrap 3733.
## 3 Gentoo    5092.</code></pre>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penguins</span> <span class="op">%&gt;%</span> <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span>  <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">species</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>median <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">body_mass_g</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   species   median
##   &lt;fct&gt;      &lt;dbl&gt;
## 1 Adelie      3700
## 2 Chinstrap   3700
## 3 Gentoo      5050</code></pre>
<p>Comment on how the descriptive statistics correspond to the box plots.</p>
</div>
<div id="measures-of-spread-quartiles-and-variances" class="section level2" number="3.5">
<h2>
<span class="header-section-number">3.5</span> Measures of spread: quartiles and variances<a class="anchor" aria-label="anchor" href="#measures-of-spread-quartiles-and-variances"><i class="fas fa-link"></i></a>
</h2>
<p>All random variables have spread in their values. The simplest way to describe it is by stating its range (the interval between the minimum and maximum values) and the quartiles (the medians of the two halves of the distribution).</p>
<p>A more standard measure of the spread of a distribution is the variance, defined as the expected value of the squared differences from the mean:</p>
<p><span class="math display">\[\text{Var}(X) = E [X - E(X)]^2 = \sum_i (a_i- E(X))^2 f(a_i)\]</span></p>
<p>And for a density function it is defined using the integral:
<span class="math display">\[\text{Var}(Y) =  E[ Y - E(Y)]^2 = \int_R (y-E(Y))^2 g(y) dy \]</span></p>
<p>Variances have squared units so they are not directly comparable to the values of the random variable. Taking the square root of the variance converts it into the same units and is called the standard deviation of the distribution:
<span class="math display">\[ \sigma_X = \sqrt{\text{Var}(X)}\]</span>
<strong>Example:</strong> Let’s go back to the penguins data set and calculate the measures of spread for the variable body mass for different penguin species</p>
<div class="sourceCode" id="cb302"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ggplot</span><span class="op">(</span>data <span class="op">=</span> <span class="va">penguins</span><span class="op">)</span> <span class="op">+</span> <span class="fu">aes</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">species</span><span class="op">)</span>, y<span class="op">=</span><span class="va">body_mass_g</span><span class="op">)</span> <span class="op">+</span> <span class="fu">geom_boxplot</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## Warning: Removed 2 rows containing non-finite values (stat_boxplot).</code></pre>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-113-1.png" width="672"></div>
<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penguins</span> <span class="op">%&gt;%</span> <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">species</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>var <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">var</a></span><span class="op">(</span><span class="va">body_mass_g</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   species       var
##   &lt;fct&gt;       &lt;dbl&gt;
## 1 Adelie    210332.
## 2 Chinstrap 147713.
## 3 Gentoo    251478.</code></pre>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penguins</span> <span class="op">%&gt;%</span> <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">species</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>first_quart <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">body_mass_g</span>,<span class="fl">0.25</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   species   first_quart
##   &lt;fct&gt;           &lt;dbl&gt;
## 1 Adelie          3362.
## 2 Chinstrap       3488.
## 3 Gentoo          4700</code></pre>
<div class="sourceCode" id="cb308"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">penguins</span> <span class="op">%&gt;%</span> <span class="fu">drop_na</span><span class="op">(</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span><span class="va">species</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>third_quart <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">body_mass_g</span>,<span class="fl">0.75</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 2
##   species   third_quart
##   &lt;fct&gt;           &lt;dbl&gt;
## 1 Adelie           4000
## 2 Chinstrap        3950
## 3 Gentoo           5500</code></pre>
<p>Which species has a wider spread in its body mass? How do the descriptive stats and the box plots correspond?</p>
</div>
<div id="data-as-samples-from-distributions-statistics" class="section level2" number="3.6">
<h2>
<span class="header-section-number">3.6</span> Data as samples from distributions: statistics<a class="anchor" aria-label="anchor" href="#data-as-samples-from-distributions-statistics"><i class="fas fa-link"></i></a>
</h2>
<p>In scientific practice, we collect data from one or more random variables, called a <em>sample</em>, and then try to make sense of it. One of the basic goals is statistical inference: using the data set to describe the <em>population</em> distribution from which the sample was drawn. Data sets can be plotted as <em>histograms</em> and the frequency/fraction of each value should be an approximation of the underlying probability distribution. In addition, descriptive statistics of the sample data (means, variances, medians, etc.) can be used to estimate the true parameters such as the mean and the variance of the population distribution.</p>
<p>Some of the fundamental questions about the population include:</p>
<ol style="list-style-type: decimal">
<li><p>What type of distribution is it?</p></li>
<li><p>Estimate the parameters of that distribution.</p></li>
<li><p>Test a hypothesis, e.g., whether two samples were drawn from the same distribution.</p></li>
<li><p>Describe and test a relationship between two or more variables.</p></li>
</ol>
<div id="law-of-large-numbers" class="section level3" number="3.6.1">
<h3>
<span class="header-section-number">3.6.1</span> Law of large numbers<a class="anchor" aria-label="anchor" href="#law-of-large-numbers"><i class="fas fa-link"></i></a>
</h3>
<p>First, the sample has to be <em>unbiased</em>, that is, no outcomes should be systematically over- or under-represented. But even an unbiased sample will differ from the population due to the inherent randomness of selection (sampling error). The <strong>law of large numbers</strong> states that as the <em>sample size</em> increases, the mean of the sample converges to the true mean of the population. Formally, for a set of <span class="math inline">\(n\)</span> independent, identically distributed random variables (the sample) <span class="math inline">\(\{X_i\}\)</span> the sample mean <span class="math inline">\(\overline{X}_n\)</span> converges to the mean of the distribution <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[ 
\lim _{n \to \infty} \frac{\sum_{i=1}^n {X_i}}{n} = \lim _{n \to \infty} \overline{X}_n = \mu
\]</span></p>
</div>
<div id="central-limit-theorem" class="section level3" number="3.6.2">
<h3>
<span class="header-section-number">3.6.2</span> Central Limit Theorem<a class="anchor" aria-label="anchor" href="#central-limit-theorem"><i class="fas fa-link"></i></a>
</h3>
<p>That is nice to know, but doesn’t say exactly how large a sample is needed to estimate, for example, the mean of the population to a given precision. For that, we have the <strong>Central Limit Theorem</strong>, which states that the distribution of sample means (from samples of independent, identically distributed random variables) as sample size increases, approaches the normal (Gaussian) distribution with mean equal to the population mean and standard deviation equal to the standard deviation of the population divided by the square root of the sample size. Formally, it states that for a set of <span class="math inline">\(n\)</span> independent, identically distributed random variables (the sample) <span class="math inline">\(\{X_i\}\)</span> with distribution mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, the probability density function of the sample mean <span class="math inline">\(\overline{X}_n\)</span> converges for large sample size <span class="math inline">\(n\)</span> to the normal distribution:</p>
<p><span class="math display">\[ 
P(\overline{X}_n) \to N(\mu, \sigma^2/n)
\]</span></p>
<p>where <span class="math inline">\(N(\mu, \sigma^2/n\)</span>) stands for the normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2/n\)</span>. One extremely useful consequence of this theorem is that the variance of the sample mean is reciprocally related to the sample size <span class="math inline">\(n\)</span>. More precisely, it allows the calculation of <em>confidence intervals</em> by using the normal distribution to generate an interval around the observed sample mean in which the true mean <span class="math inline">\(\mu\)</span> lies with a given likelihood.</p>
<p>This is an amazing result because it applies to any distribution, so it allows for the estimation of means for any situation, as long as the condition of independent, identically distributed variables in the sample is satisfied (the identical distributed condition can actually be relaxed). There are other central limit theorems that apply to other situations, including cases where the random variables in the sample are not independent (e.g., Markov models). The bottom line is that an unbiased sample contains a reflection of the true population, but it is always distorted by uncertainty. Larger sample sizes decrease the uncertainty but are more difficult and expensive to obtain.</p>
<p><strong>Discussion:</strong> Suggest examples of biological data sets which are not made up of independent identically distributed random variables.</p>
</div>
</div>
<div id="exploration-misleading-means" class="section level2" number="3.7">
<h2>
<span class="header-section-number">3.7</span> Exploration: misleading means<a class="anchor" aria-label="anchor" href="#exploration-misleading-means"><i class="fas fa-link"></i></a>
</h2>
<p>Means are the most common type of descriptive statistic and are sometimes the only numeric quantity used to compare two data sets, e.g. “the average GPA at school A is 3.5 vs 3.8 at school B.” However, means can be misleading measures in multiple ways.</p>
<p>First, means are highly sensitive to outliers, or points that are very different from other values. They can skew the mean value, even pulling it completely away from the bulk of the values, in which case the mean ceases to be a measure of a “typical” value.</p>
<p>Second, there can be funny business with combining means of different <em>subsets</em> of data. Normally, you might expect if you have group A and group B, and each group has two subgroups divided by another variable (e.g. we are comparing the GPAs of students in school A and school B, and we split up the students in each school by gender), then if the means of each subgroup of A and larger than the means of the same subgroup of B (e.g. the GPA of girls and boys in school A are higher than those of their counterparts in school B), then the same relationship should be true for the combined mean of group A and group B (that is, the overall GPA in school A is higher than school B). That is not necessarily true!</p>
<p>This apparent contradiction is called Simpson’s paradox. It can be illustrated in the data set of all the passengers and crew on the doomed ocean liner Titanic. The data set is found in the library <code>stablelearner</code> and is loaded by the chunk below:</p>
<div class="sourceCode" id="cb310"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">stablelearner</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">titanic</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">titanic</span><span class="op">)</span></code></pre></div>
<pre><code>## 'data.frame':    2207 obs. of  11 variables:
##  $ name    : chr  "Abbing, Mr. Anthony" "Abbott, Mr. Eugene Joseph" "Abbott, Mr. Rossmore Edward" "Abbott, Mrs. Rhoda Mary 'Rosa'" ...
##  $ gender  : Factor w/ 2 levels "female","male": 2 2 2 1 1 2 2 1 2 2 ...
##  $ age     : num  42 13 16 39 16 25 30 28 27 20 ...
##  $ class   : Factor w/ 7 levels "1st","2nd","3rd",..: 3 3 3 3 3 3 2 2 3 3 ...
##  $ embarked: Factor w/ 4 levels "B","C","Q","S": 4 4 4 4 4 4 2 2 2 4 ...
##  $ country : Factor w/ 48 levels "Argentina","Australia",..: 44 44 44 15 30 44 17 17 26 16 ...
##  $ ticketno: int  5547 2673 2673 2673 348125 348122 3381 3381 2699 3101284 ...
##  $ fare    : num  7.11 20.05 20.05 20.05 7.13 ...
##  $ sibsp   : Ord.factor w/ 9 levels "0"&lt;"1"&lt;"2"&lt;"3"&lt;..: 1 1 2 2 1 1 2 2 1 1 ...
##  $ parch   : Ord.factor w/ 10 levels "0"&lt;"1"&lt;"2"&lt;"3"&lt;..: 1 3 2 2 1 1 1 1 1 1 ...
##  $ survived: Factor w/ 2 levels "no","yes": 1 1 1 2 2 2 1 2 2 2 ...</code></pre>
<p>The chunk below calculated the survival probability of passengers of all classes compared to the crew (of all types:</p>
<div class="sourceCode" id="cb312"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">titanic</span> <span class="op">%&gt;%</span> <span class="fu">group_by</span><span class="op">(</span>Passenger <span class="op">=</span> <span class="va">class</span> <span class="op">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'1st'</span>, <span class="st">'2nd'</span>, <span class="st">'3rd'</span><span class="op">)</span>, <span class="va">survived</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">summarise</span><span class="op">(</span>num <span class="op">=</span> <span class="fu">n</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span> <span class="fu">mutate</span><span class="op">(</span>fraction <span class="op">=</span> <span class="va">num</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">num</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
<pre><code>## `summarise()` has grouped output by 'Passenger'. You can override using the `.groups` argument.</code></pre>
<pre><code>## # A tibble: 4 × 4
## # Groups:   Passenger [2]
##   Passenger survived   num fraction
##   &lt;lgl&gt;     &lt;fct&gt;    &lt;int&gt;    &lt;dbl&gt;
## 1 FALSE     no         679    0.763
## 2 FALSE     yes        211    0.237
## 3 TRUE      no         817    0.620
## 4 TRUE      yes        500    0.380</code></pre>
<p>You can see that about 24% of the crew survived and almost 38% of the passengers survived. In this week’s assignment you will calculate and explain what happens when you divide the people in each group by gender.</p>
</div>
<div id="references" class="section level2" number="3.8">
<h2>
<span class="header-section-number">3.8</span> References<a class="anchor" aria-label="anchor" href="#references"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://www.bayesianspectacles.org/laplaces-demon/">Laplace’s views on probability and determinism</a></li>
<li><a href="https://medium.com/@ODSC/exploring-the-central-limit-theorem-in-r-e2a2f7091606">Central Limit Theorem in R</a></li>
<li><a href="https://genomicsclass.github.io/book/pages/clt_in_practice.html">Exploration of the Central Limit Theorem</a></li>
<li><a href="https://medium.com/@nikhilborkar/the-simpsons-paradox-and-where-to-find-them-cfcec6c2d8b3">Simpson’s paradox</a></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="visualizing-data-using-ggplot2.html"><span class="header-section-number">2</span> Visualizing data using ggplot2</a></div>
<div class="next"><a href="data-wrangling.html"><span class="header-section-number">4</span> Data wrangling</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#fundamentals-of-probability"><span class="header-section-number">3</span> Fundamentals of probability</a></li>
<li><a class="nav-link" href="#sample-spaces-and-random-variables"><span class="header-section-number">3.1</span> Sample spaces and random variables</a></li>
<li><a class="nav-link" href="#probability-axioms"><span class="header-section-number">3.2</span> Probability axioms</a></li>
<li><a class="nav-link" href="#probability-distributions"><span class="header-section-number">3.3</span> Probability distributions</a></li>
<li><a class="nav-link" href="#measures-of-center-medians-and-means"><span class="header-section-number">3.4</span> Measures of center: medians and means</a></li>
<li><a class="nav-link" href="#measures-of-spread-quartiles-and-variances"><span class="header-section-number">3.5</span> Measures of spread: quartiles and variances</a></li>
<li>
<a class="nav-link" href="#data-as-samples-from-distributions-statistics"><span class="header-section-number">3.6</span> Data as samples from distributions: statistics</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#law-of-large-numbers"><span class="header-section-number">3.6.1</span> Law of large numbers</a></li>
<li><a class="nav-link" href="#central-limit-theorem"><span class="header-section-number">3.6.2</span> Central Limit Theorem</a></li>
</ul>
</li>
<li><a class="nav-link" href="#exploration-misleading-means"><span class="header-section-number">3.7</span> Exploration: misleading means</a></li>
<li><a class="nav-link" href="#references"><span class="header-section-number">3.8</span> References</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentals of Biological Data Analysis</strong>" was written by Dmitry Kondrashov and Stefano Allesina. It was last built on 2021-11-10.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
