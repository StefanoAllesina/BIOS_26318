<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Lecture 14 Generalized linear models | Fundamentals of Biological Data Analysis</title>
<meta name="author" content="Dmitry Kondrashov and Stefano Allesina">
<meta name="description" content="14.1 Goal Learn about Generalized Linear Models (GLMs), and be able to decide which model is most appropriate for the problem at hand. Let’s load some packages: library(tidyverse) # our friend the...">
<meta name="generator" content="bookdown 0.29 with bs4_book()">
<meta property="og:title" content="Lecture 14 Generalized linear models | Fundamentals of Biological Data Analysis">
<meta property="og:type" content="book">
<meta property="og:description" content="14.1 Goal Learn about Generalized Linear Models (GLMs), and be able to decide which model is most appropriate for the problem at hand. Let’s load some packages: library(tidyverse) # our friend the...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lecture 14 Generalized linear models | Fundamentals of Biological Data Analysis">
<meta name="twitter:description" content="14.1 Goal Learn about Generalized Linear Models (GLMs), and be able to decide which model is most appropriate for the problem at hand. Let’s load some packages: library(tidyverse) # our friend the...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentals of Biological Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Organization of the class</a></li>
<li><a class="" href="refresher.html"><span class="header-section-number">1</span> Refresher</a></li>
<li><a class="" href="visualizing-data-using-ggplot2.html"><span class="header-section-number">2</span> Visualizing data using ggplot2</a></li>
<li><a class="" href="fundamentals-of-probability.html"><span class="header-section-number">3</span> Fundamentals of probability</a></li>
<li><a class="" href="data-wrangling.html"><span class="header-section-number">4</span> Data wrangling</a></li>
<li><a class="" href="distributions-and-their-properties.html"><span class="header-section-number">5</span> Distributions and their properties</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">6</span> Hypothesis testing</a></li>
<li><a class="" href="likelihood-and-bayes.html"><span class="header-section-number">7</span> Likelihood and Bayes</a></li>
<li><a class="" href="review-of-linear-algebra.html"><span class="header-section-number">8</span> Review of linear algebra</a></li>
<li><a class="" href="linear-models.html"><span class="header-section-number">9</span> Linear models</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">10</span> ANOVA</a></li>
<li><a class="" href="model-selection.html"><span class="header-section-number">11</span> Model Selection</a></li>
<li><a class="" href="principal-component-analysis.html"><span class="header-section-number">12</span> Principal Component Analysis</a></li>
<li><a class="" href="clustering.html"><span class="header-section-number">13</span> Clustering</a></li>
<li><a class="active" href="generalized-linear-models.html"><span class="header-section-number">14</span> Generalized linear models</a></li>
<li><a class="" href="machine-learning-methods-for-classification.html"><span class="header-section-number">15</span> Machine learning methods for classification</a></li>
<li><a class="" href="building-phylogeneric-trees.html"><span class="header-section-number">16</span> Building phylogeneric trees</a></li>
<li><a class="" href="time-series-modeling-and-forecasting.html"><span class="header-section-number">17</span> Time series: modeling and forecasting</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="generalized-linear-models" class="section level1" number="14">
<h1>
<span class="header-section-number">Lecture 14</span> Generalized linear models<a class="anchor" aria-label="anchor" href="#generalized-linear-models"><i class="fas fa-link"></i></a>
</h1>
<div id="goal-4" class="section level2" number="14.1">
<h2>
<span class="header-section-number">14.1</span> Goal<a class="anchor" aria-label="anchor" href="#goal-4"><i class="fas fa-link"></i></a>
</h2>
<p>Learn about Generalized Linear Models (GLMs), and be able to decide which model is most appropriate for the problem at hand.</p>
<p>Let’s load some packages:</p>
<div class="sourceCode" id="cb812"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span> <span class="co"># our friend the tidyverse</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.stats.ox.ac.uk/pub/MASS4/">MASS</a></span><span class="op">)</span> <span class="co"># negative binom regression</span></span></code></pre></div>
</div>
<div id="introduction" class="section level2" number="14.2">
<h2>
<span class="header-section-number">14.2</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction"><i class="fas fa-link"></i></a>
</h2>
<p>The linear regression we’ve explored during the past weeks attempts to estimate the expected value for <strong>response</strong> (dependent) variable <span class="math inline">\(Y\)</span> given the <strong>predictors</strong> <span class="math inline">\(X\)</span>. It assumes that the response variable changes continuously, and that errors are normally distributed around the mean. In many cases, however:</p>
<ul>
<li>the response variable does not have support in the whole real line (e.g., binary, count, only positive values)</li>
<li>the errors are not normally distributed (e.g., the response variable can take only positive values)</li>
<li>the variance changes with the mean (heteroscedasticity)</li>
</ul>
<p>In these cases, you can use <strong>Generalized Linear Models</strong> (GLMs) to fit the data. In the simplest form of GLMs,</p>
<ul>
<li>The response variable is modeled by a single-parameter distribution from the exponential family (Gaussian, Gamma, Binomial, Poisson, etc.)</li>
<li>A <strong>link function</strong> linearizes the relationship between the fitted values and the predictors.</li>
<li>Parameters are estimated through a least squares algorithm.</li>
</ul>
<div id="model-structure" class="section level3" number="14.2.1">
<h3>
<span class="header-section-number">14.2.1</span> Model structure<a class="anchor" aria-label="anchor" href="#model-structure"><i class="fas fa-link"></i></a>
</h3>
<p>In practice, we need to determine three parts of the model:</p>
<ul>
<li>
<strong>Random component</strong> the entries of the response variable (<span class="math inline">\(Y\)</span>) are assumed to be independently drawn from a certain distribution (e.g., Binomial)—typically a distribution that can be modeled using a single parameter.</li>
<li>
<strong>Systematic component</strong> the explanatory variables (<span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(\ldots\)</span>) are combined linearly to form a <strong>linear predictor</strong> (e.g., <span class="math inline">\(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \ldots\)</span>). The explanatory variables can be continuous, categorical, or mixed.</li>
<li>
<strong>Link function</strong> <span class="math inline">\(g(u)\)</span> specifies how the random and systematic components are connected.</li>
</ul>
</div>
</div>
<div id="binary-data" class="section level2" number="14.3">
<h2>
<span class="header-section-number">14.3</span> Binary data<a class="anchor" aria-label="anchor" href="#binary-data"><i class="fas fa-link"></i></a>
</h2>
<p>The most extreme case of departure from normality is when the response variable can assume only values 0 or 1 (no/yes, survived/deceased, lost/won, etc.). A Bernoulli random variable can take values 0 or 1, and therefore provides the <strong>Random component</strong> of the model:</p>
<p><span class="math display">\[
P(Y_i = y_i | \pi_i) = \pi_i^{y_i} (1 - \pi_i)^{1 - y_i}
\]</span></p>
<p>Saying that the probability <span class="math inline">\(P(Y_i = 1) = \pi_i\)</span>, and <span class="math inline">\(P(Y_i = 0) = 1 - \pi_i\)</span>. Now we want to relate the parameter <span class="math inline">\(\pi_i\)</span> to the <strong>linear predictor</strong> (i.e., choose a link function). This can be accomplished in a number of ways.</p>
<div id="logistic-regression" class="section level3" number="14.3.1">
<h3>
<span class="header-section-number">14.3.1</span> Logistic regression<a class="anchor" aria-label="anchor" href="#logistic-regression"><i class="fas fa-link"></i></a>
</h3>
<p>The most popular choice is to use the <strong>Logit</strong> function as the <strong>link function</strong>:</p>
<p><span class="math display">\[
\text{Logit}(\pi_i) = \beta_0 + \beta_1 x_i
\]</span></p>
<p>where the function can be written as:</p>
<p><span class="math display">\[
\text{Logit}(\pi_i) = \log\left( \frac{\pi_i}{1 - \pi_i} \right) = \log(\pi_i) - \log(1 - \pi_i)
\]</span></p>
<p>Practically, this means that</p>
<p><span class="math display">\[
\pi_i = \frac{e^{\beta_0 + \beta_1 x_i}}{1 + e^{\beta_0 + \beta_1 x_i}} = 1 - \frac{1}{1 + e^{\beta_0 + \beta_1 x_i}}
\]</span></p>
<p>Clearly, when <span class="math inline">\(\beta_0 + \beta_1 x_i = 0\)</span>, the probability <span class="math inline">\(\pi_i = 1/2\)</span>, while the probability tends to 1 when <span class="math inline">\((\beta_0 + \beta_1 x_i) \to \infty\)</span> and to zero when <span class="math inline">\((\beta_0 + \beta_1 x_i) \to -\infty\)</span>. :</p>
<div class="sourceCode" id="cb813"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># some random data</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">beta_0</span> <span class="op">&lt;-</span> <span class="fl">0.35</span></span>
<span><span class="va">beta_1</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">3.2</span></span>
<span><span class="va">linear_predictor</span> <span class="op">&lt;-</span> <span class="va">beta_0</span> <span class="op">+</span> <span class="va">beta_1</span> <span class="op">*</span> <span class="va">X</span></span>
<span><span class="va">predicted_pi_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">linear_predictor</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">linear_predictor</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span>data <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>linear_predictor <span class="op">=</span> <span class="va">linear_predictor</span>, probability <span class="op">=</span> <span class="va">predicted_pi_i</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">linear_predictor</span>, y <span class="op">=</span> <span class="va">probability</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-336-1.png" width="672"></div>
<p>As you can see, this is a logistic curve, hence the name. The parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> control the location of the inflection point and the steepness of the curve, allowing you to model binary response variables (and, with a slight abuse of the error structure, proportions or probabilities).</p>
<p>Other choices of link functions are possible. For example, in economics the <em>probit</em> function is preferred:</p>
<p><span class="math display">\[
\text{Probit}(\pi_i) = \beta_0 + \beta_1 x_i
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\text{Probit}(\pi_i) = \Phi(\pi_i)
\]</span>
and <span class="math inline">\(\Phi(\cdot)\)</span> is the cumulative distribution function of the standard normal normal distribution:</p>
<p><span class="math display">\[
\Phi(z) = \frac{1}{\sqrt{2 \pi}}\int_{-\infty}^z e^{\frac{-t^2}{2}} dt
\]</span>
Clearly, you could alternatively use the cumulative distribution function of any distribution that has support on the real line.</p>
</div>
<div id="a-simple-example" class="section level3" number="14.3.2">
<h3>
<span class="header-section-number">14.3.2</span> A simple example<a class="anchor" aria-label="anchor" href="#a-simple-example"><i class="fas fa-link"></i></a>
</h3>
<p>We want to know whether being in first, second and third class, as well as gender (women and women first!) influenced the probability of survival in the Titanic disaster. We start with a null model (all passengers have the same probability of survival):</p>
<div class="sourceCode" id="cb814"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/paulhendricks/titanic">titanic</a></span><span class="op">)</span></span>
<span><span class="co"># model 0: probability of survival in general</span></span>
<span><span class="co"># regress against an intercept</span></span>
<span><span class="va">model0</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Survived</span> <span class="op">~</span> <span class="fl">1</span>, <span class="co"># only intercept</span></span>
<span>              data <span class="op">=</span> <span class="va">titanic_train</span>, </span>
<span>              family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span> <span class="co"># logistic regression</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model0</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ 1, family = "binomial", data = titanic_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9841  -0.9841  -0.9841   1.3839   1.3839  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -0.47329    0.06889   -6.87  6.4e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1186.7  on 890  degrees of freedom
## Residual deviance: 1186.7  on 890  degrees of freedom
## AIC: 1188.7
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb816"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># the best fitting (alpha) intercept should lead to </span></span>
<span><span class="co"># e^alpha / (1 + e^alpha) = mean(Survived)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">titanic_train</span><span class="op">$</span><span class="va">Survived</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.3838384</code></pre>
<div class="sourceCode" id="cb818"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">model0</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">model0</span><span class="op">$</span><span class="va">coefficients</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## (Intercept) 
##   0.3838384</code></pre>
<p>Now let’s include gender:</p>
<div class="sourceCode" id="cb820"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Survived</span> <span class="op">~</span> <span class="va">Sex</span>, <span class="co"># one sex as baseline, the other modifies intercept</span></span>
<span>              data <span class="op">=</span> <span class="va">titanic_train</span>,</span>
<span>              family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Sex, family = "binomial", data = titanic_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.6462  -0.6471  -0.6471   0.7725   1.8256  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   1.0566     0.1290   8.191 2.58e-16 ***
## Sexmale      -2.5137     0.1672 -15.036  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1186.7  on 890  degrees of freedom
## Residual deviance:  917.8  on 889  degrees of freedom
## AIC: 921.8
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>What is the best-fitting probability of survival for male/female?</p>
<div class="sourceCode" id="cb822"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coeffs</span> <span class="op">&lt;-</span> <span class="va">model1</span><span class="op">$</span><span class="va">coefficients</span></span>
<span><span class="co"># prob women</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coeffs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.7420382</code></pre>
<div class="sourceCode" id="cb824"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># prob men</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coeffs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.1889081</code></pre>
<p>Now let’s see whether we can explain better the data using the class:</p>
<div class="sourceCode" id="cb826"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Survived</span> <span class="op">~</span> <span class="va">Sex</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Pclass</span><span class="op">)</span>, <span class="co"># combine Sex and Pclass</span></span>
<span>              data <span class="op">=</span> <span class="va">titanic_train</span>,</span>
<span>              family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Survived ~ Sex + factor(Pclass), family = "binomial", 
##     data = titanic_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1877  -0.7312  -0.4476   0.6465   2.1681  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       2.2971     0.2190  10.490  &lt; 2e-16 ***
## Sexmale          -2.6419     0.1841 -14.351  &lt; 2e-16 ***
## factor(Pclass)2  -0.8380     0.2447  -3.424 0.000618 ***
## factor(Pclass)3  -1.9055     0.2141  -8.898  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1186.66  on 890  degrees of freedom
## Residual deviance:  826.89  on 887  degrees of freedom
## AIC: 834.89
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>A woman in first class would have survival probability:</p>
<div class="sourceCode" id="cb828"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coeffs</span> <span class="op">&lt;-</span> <span class="va">model2</span><span class="op">$</span><span class="va">coefficients</span></span>
<span><span class="co"># prob women first class</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coeffs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.9086385</code></pre>
<p>While a man in third class:</p>
<div class="sourceCode" id="cb830"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coeffs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 0.09532814</code></pre>
<p>Consider the alternative models <code>Survived ~ Sex * factor(Pclass)</code>, <code>Survived ~ Sex + Pclass</code>, <code>Survived ~ Sex * Pclass</code>, <code>Survived ~ Sex:factor(Pclass)</code>, <code>Survived ~ Sex:Pclass</code>. Explain what each model is doing in English.</p>
</div>
<div id="exercise-in-class-college-admissions" class="section level3" number="14.3.3">
<h3>
<span class="header-section-number">14.3.3</span> Exercise in class: College admissions<a class="anchor" aria-label="anchor" href="#exercise-in-class-college-admissions"><i class="fas fa-link"></i></a>
</h3>
<p>With slight abuse of notation, you can fit probabilities using the logistic regression (the only problem is that you don’t know how many values contributed to the calculations of the probabilities—i.e., sample sizes). Read in the file <code>admission_rates.csv</code>, containing data on admissions to several universities. Your goal is to find a good prediction (or a good combination of predictors) for the <code>Admission_rate</code>. You can use <code>State</code>, <code>Ownership</code> (public/private), <code>Citytype</code> (town, suburb, city), <code>SAT</code> (typical SAT score of admits), <code>AvgCost</code> (tuition). Fit the models using:</p>
<div class="sourceCode" id="cb832"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"data/admission_rates.csv"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Rows: 195 Columns: 7
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: ","
## chr (4): Name, State, Ownership, Citytype
## dbl (3): SAT, AvgCost, Admission_rate
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<div class="sourceCode" id="cb834"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># example</span></span>
<span><span class="va">logit_1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Admission_rate</span> <span class="op">~</span> <span class="va">AvgCost</span>, data <span class="op">=</span> <span class="va">dt</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Warning in eval(family$initialize): non-integer #successes in a binomial glm!</code></pre>
<p>(do not worry about the warning <code>non-integer #successes in a binomial glm!</code>).</p>
<ul>
<li>Plot fitted vs. observed admission rates, when using different combinations of predictors.</li>
</ul>
<p>For the example above:</p>
<div class="sourceCode" id="cb836"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dt</span><span class="op">$</span><span class="va">Admission_rate</span>, <span class="va">logit_1</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="BIOS_26318_2020_files/figure-html/unnamed-chunk-344-1.png" width="672"></div>
<ul>
<li>Score the models using <code>AIC</code>: which is the single best predictor of acceptance rate? (Note: as we will see later this week, the lower the AIC, the better).</li>
</ul>
<div class="sourceCode" id="cb837"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">logit_1</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 220.7783</code></pre>
<ul>
<li>Which the best combination of two predictors?</li>
</ul>
</div>
</div>
<div id="count-data" class="section level2" number="14.4">
<h2>
<span class="header-section-number">14.4</span> Count data<a class="anchor" aria-label="anchor" href="#count-data"><i class="fas fa-link"></i></a>
</h2>
<div id="poisson-regression" class="section level3" number="14.4.1">
<h3>
<span class="header-section-number">14.4.1</span> Poisson regression<a class="anchor" aria-label="anchor" href="#poisson-regression"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose your response variables are non-negative integers. For example, we are counting the number of eggs females lay as a function of their age, body size, etc. A possible model for this case is to think of the response variable as being sampled from a Poisson distribution:</p>
<p><span class="math display">\[
Y_i \sim \text{Pois}(\lambda_i)
\]</span></p>
<p>and that the logarithm of the parameter <span class="math inline">\(\lambda_i\)</span> depends linearly on the predictors:</p>
<p><span class="math display">\[
\mathbb E[\lambda_i] = \mathbb E[\log(Y_i|X_i)] = \beta_0 + \beta_1 X_i
\]</span></p>
<p>In this case, our <em>link function</em> is the logarithm, transforming the relationship between the fitted values and the predictors into a linear regression.</p>
</div>
<div id="exercise-in-class-number-of-genomes" class="section level3" number="14.4.2">
<h3>
<span class="header-section-number">14.4.2</span> Exercise in class: Number of genomes<a class="anchor" aria-label="anchor" href="#exercise-in-class-number-of-genomes"><i class="fas fa-link"></i></a>
</h3>
<p>The file <code>data/genomes.csv</code> contains the year in which the genome of a given animal was published. The file <code>sequence_cost.csv</code> the estimated cost per sequencing a Mb in a given year.</p>
<ul>
<li>Count the number of genomes published per year (store the value as <code>n</code>) and store it in the tibble <code>num_genomes</code> along with the values <code>Year</code> and <code>Dollars_per_Mb</code> (note: you need to use <code>inner_join</code> to pull this off);</li>
<li>Fit the number of genomes published in a given year:
<ul>
<li>using only an intercept (your predictions should match the mean) (Code: <code>pois_1 &lt;- glm(n ~ 1, data = num_genomes, family = "poisson")</code>)</li>
<li>using the year as a predictor</li>
<li>using the cost of sequencing as a predictor</li>
</ul>
</li>
<li>For each model, plot the observed <code>n</code> vs its predicted value, and compute AIC. Is the fit superior when we use <code>Year</code> or <code>Dollars_per_Mb</code>?</li>
</ul>
</div>
<div id="underdispersed-and-overdispersed-data" class="section level3" number="14.4.3">
<h3>
<span class="header-section-number">14.4.3</span> Underdispersed and Overdispersed data<a class="anchor" aria-label="anchor" href="#underdispersed-and-overdispersed-data"><i class="fas fa-link"></i></a>
</h3>
<p>The main feature of the Poisson distribution is that the mean and the variance are both equal to <span class="math inline">\(\lambda\)</span>. You might remember (Taylor expansion) that:</p>
<p><span class="math display">\[
e^x = \sum_{n = 0}^{\infty} \frac{x^n}{n!}
\]</span></p>
<p>Then, for <span class="math inline">\(X\)</span> sampled from a Poisson distribution:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb E[X] &amp;= \sum_{x = 0}^{\infty} x P(X = x) \\
&amp;= \sum_{x = 0}^{\infty} x e^{-\lambda} \frac{\lambda^x}{x!} \\
&amp;= \lambda e^{-\lambda} \sum_{(x - 1) = 0}^{\infty} \frac{\lambda^{(x-1)}}{(x-1)!} \\
&amp;= \lambda e^{-\lambda}e^{\lambda} \\
&amp;= \lambda
\end{aligned}
\]</span></p>
<p>Similarly, using</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb V[X] &amp;= \mathbb E[X^2]-\mathbb E[X]^2\\
&amp;= \left(\sum_{x = 0}^{\infty} x^2 e^{-\lambda} \frac{\lambda^x}{x!} \right) - \lambda^2 \\
&amp;= \ldots\\
&amp;= \lambda
\end{aligned}
\]</span></p>
<p>The fact that the variance equals the mean is a hard constraint, rarely matched by real data. When you encounter <strong>over-dispersion</strong> (i.e., the variance in the data is much larger than what assumed by Poisson), you need to choose a different model. This happens very often, and the main solution to use is a <strong>Negative Binomial Regression</strong> (a negative binomial distribution can be thought of as a Poisson with a scaled variance). In practice, this amounts to fitting:</p>
<p><span class="math display">\[
\mathbb E[\lambda_i] = \beta_0 + \beta_1 X_i
\]</span>
and</p>
<p><span class="math display">\[
\mathbb E[\lambda_i^2] - \mathbb E[\lambda_i]^2 = \mathbb V[\lambda_i] = \phi \lambda_i
\]</span>
Where <span class="math inline">\(\phi\)</span> controls the dispersion of the data. A value <span class="math inline">\(\phi &gt; 1\)</span> signals over-dispersion, while (the very rare case of) <span class="math inline">\(\phi &lt; 1\)</span> under-dispersion. The Poisson regression is appropriate only when <span class="math inline">\(\phi \approx 1\)</span>. A simple way to test for dispersion in to fit a <code>quasipoisson</code> model, which returns a dispersion parameter (anything larger than 1 means over-dispersion).</p>
</div>
<div id="exercise-in-class-number-of-genomes-1" class="section level3" number="14.4.4">
<h3>
<span class="header-section-number">14.4.4</span> Exercise in class: Number of genomes<a class="anchor" aria-label="anchor" href="#exercise-in-class-number-of-genomes-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>For the models above, change the family to <code>quasipoisson</code> to check the dispersion (e.g., <code>qpois_1 &lt;- glm(n ~ 1, data = num_genomes, family = "quasipoisson")</code>).</li>
<li>Do you have over-dispersion?</li>
<li>If the data are over-dispersed, fit them again using <code>glm.nb</code> (a negative binomial regression model provided by the package <code>MASS</code>).</li>
</ul>
</div>
<div id="separate-distribution-for-the-zeros" class="section level3" number="14.4.5">
<h3>
<span class="header-section-number">14.4.5</span> Separate distribution for the zeros<a class="anchor" aria-label="anchor" href="#separate-distribution-for-the-zeros"><i class="fas fa-link"></i></a>
</h3>
<p>In several biologically-relevant cases, we have an excess of zeros. For example, you might have animals, that, if they reach the age of 1, will go on to a live a number of years—say well-described by a Poisson distribution. However, mortality immediately after birth is high. In such cases, you can use zero-inflated or zero-hurdle models.</p>
<p>In zero-inflated models, you can think of having a conditional branching: with probability <span class="math inline">\(p_z\)</span> your count is zero; if not (prob. <span class="math inline">\(1-p_z\)</span>) it is sampled from a given distribution. As such a count of zero can stem from two different processes: either because you got a zero at the first step, or because you have sampled a zero from the distribution.</p>
<p>Zero-hurdle models are slightly different: you first decide whether you’re going to have a zero; if not, you sample your data from a truncated distribution, such that you cannot sample a zero from this second source.</p>
<p>Zero-inflated and zero-hurdle models are examples of <a href="https://en.wikipedia.org/wiki/Mixture_model"><strong>mixture models</strong></a>.</p>
</div>
</div>
<div id="other-glms" class="section level2" number="14.5">
<h2>
<span class="header-section-number">14.5</span> Other GLMs<a class="anchor" aria-label="anchor" href="#other-glms"><i class="fas fa-link"></i></a>
</h2>
<p>Historically, GLMs have been defined for the canonical families:</p>
<ul>
<li>Gaussian: linear regression</li>
<li>Gamma and Inverse Gaussian: Positive, continuous</li>
<li>Poisson: count data</li>
<li>Negative Binomial: count data (fit an ancillary parameter for over-dispersion)</li>
<li>Binary/Binomial (logistic): binary responses; number of successes; probabilities/proportions (with slight abuse).</li>
</ul>
<p>However, the same basic idea led to the development of “non-canonical” GLMs:</p>
<ul>
<li>Log-normal: Positive, continuous</li>
<li>Log-gamma: survival models</li>
<li>Probit: binary</li>
</ul>
<p>and many others. Fitting the models can be done using Maximum Likelihoods, or in a Bayesian framework (typically, through MCMC).</p>
</div>
<div id="readings-and-homework" class="section level2" number="14.6">
<h2>
<span class="header-section-number">14.6</span> Readings and homework<a class="anchor" aria-label="anchor" href="#readings-and-homework"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>There are two useful swirls in the course <code>Regression Models</code>: <code>Binary Outcomes</code> and <code>Count Outcomes</code>
</li>
<li><a href="https://link.springer.com/book/10.1007/978-1-4419-0118-7">An excellent book on GLMs in R</a></li>
<li><a href="https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf">Regression Models for Count Data in R</a></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="clustering.html"><span class="header-section-number">13</span> Clustering</a></div>
<div class="next"><a href="machine-learning-methods-for-classification.html"><span class="header-section-number">15</span> Machine learning methods for classification</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#generalized-linear-models"><span class="header-section-number">14</span> Generalized linear models</a></li>
<li><a class="nav-link" href="#goal-4"><span class="header-section-number">14.1</span> Goal</a></li>
<li>
<a class="nav-link" href="#introduction"><span class="header-section-number">14.2</span> Introduction</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#model-structure"><span class="header-section-number">14.2.1</span> Model structure</a></li></ul>
</li>
<li>
<a class="nav-link" href="#binary-data"><span class="header-section-number">14.3</span> Binary data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#logistic-regression"><span class="header-section-number">14.3.1</span> Logistic regression</a></li>
<li><a class="nav-link" href="#a-simple-example"><span class="header-section-number">14.3.2</span> A simple example</a></li>
<li><a class="nav-link" href="#exercise-in-class-college-admissions"><span class="header-section-number">14.3.3</span> Exercise in class: College admissions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#count-data"><span class="header-section-number">14.4</span> Count data</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#poisson-regression"><span class="header-section-number">14.4.1</span> Poisson regression</a></li>
<li><a class="nav-link" href="#exercise-in-class-number-of-genomes"><span class="header-section-number">14.4.2</span> Exercise in class: Number of genomes</a></li>
<li><a class="nav-link" href="#underdispersed-and-overdispersed-data"><span class="header-section-number">14.4.3</span> Underdispersed and Overdispersed data</a></li>
<li><a class="nav-link" href="#exercise-in-class-number-of-genomes-1"><span class="header-section-number">14.4.4</span> Exercise in class: Number of genomes</a></li>
<li><a class="nav-link" href="#separate-distribution-for-the-zeros"><span class="header-section-number">14.4.5</span> Separate distribution for the zeros</a></li>
</ul>
</li>
<li><a class="nav-link" href="#other-glms"><span class="header-section-number">14.5</span> Other GLMs</a></li>
<li><a class="nav-link" href="#readings-and-homework"><span class="header-section-number">14.6</span> Readings and homework</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentals of Biological Data Analysis</strong>" was written by Dmitry Kondrashov and Stefano Allesina. It was last built on 2022-10-04.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
